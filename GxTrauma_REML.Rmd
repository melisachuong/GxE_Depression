---
title: "GxTrauma_Reml"
author: "Melisa Chuong"
date: "22/08/2021"
output: 
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# ANALYSIS SAMPLE:  

The analysis sample here are participants with complete trauma data (i.e. they have responded to ALL 16 trauma sub-questions).  
Using the available trauma principal components as our environmental variables we can identify those with complete environmental data within our clusters  

```{r, eval=FALSE}
library(tidyverse)  

rm(list=ls())

grm_ids <- read.table("../grm/gxe_keepIDs.txt", header=F) #this give us the IDs of the full overlap
colnames(grm_ids) <- c("FID", "IID") # n = 148129

pcs <- read.csv("../phenotypes/trauma_pcs.csv")
total_analysis_sample <- pcs %>%
                         mutate(FID = f.eid,
                                IID = f.eid) %>%
                         select(FID, IID, PC1:PC16) %>%
                         inner_join(., grm_ids)  # n = 138248

write.table(total_analysis_sample, "trauma_profile.txt", row.names=F, quote=F)

#################################################################
#Create separate profile.txt files for each cluster             #
#Create separate total analysis sample ID files for each cluster#
#################################################################

ids <- read.table("trauma_profile.txt", header=T)

#important to merge onto the gxeKEEP IDs as this will ensure the order of the ids are the same in both GRMs and ERMs!

#creating profile.txt files for ERMs

for (cluster in c("north", "midnorth", "midsouth", "southwest", "southeast")){
  
  cluster_ids <- read.table(paste0("../grm/gxe_keepIDs_", cluster, ".txt"), header=F)
  cluster_erm_ids <- cluster_ids %>%
                     rename(FID = V1, 
                            IID = V2) %>%
                     inner_join(., ids)
  
write.table(cluster_erm_ids, paste0("trauma_", cluster,"_profile.txt"), row.names=F, quote=F)
}

#creating id files for GRMs because we need to make sure the SAME participants have GRMs and ERMs available

for (cluster in c("north", "midnorth", "midsouth", "southwest", "southeast")){
  
  cluster_ids <- read.table(paste0("../erm/trauma_", cluster, "_profile.txt"), header=T)
  cluster_ids <- cluster_ids %>%
                 select(FID, IID)

write.table(cluster_ids, paste0("gxe_keepIDs_", cluster,".txt"), col.names=F, row.names=F, quote=F)
}

#north n = 24287
#midnorth n = 29981
#midsouth n = 28961
#southwest n = 18696
#southeast n = 36323

```

# CLUSTER DEMOGRAPHICS:  

It is important to understand the age range, sex and case proportion within each cluster.

```{r, eval=FALSE}

rm(list=ls())

# basic covariates
cov <- read.table("../phenotypes/covariates", header=T)
cov <- cov %>%
       select(FID, sex, age_0initial, genotyping.array) %>%
       mutate(IID = FID) # n = 457440

#dependent variables
broad <- read.table("../phenotypes/broad_df", header=T)
colnames(broad) <- c("FID", "BROAD")

cidi <- read.table("../phenotypes/cidi_df", header=T)
colnames(cidi) <- c("FID", "CIDI")

neuro <- read.table("../phenotypes/neuro_df", header=T)
colnames(neuro) <- c("FID", "NEURO")

df <- Reduce(function(x,y) merge(x=x, y=y, by="FID", all.x=T, all.y=T), list(cov,broad,cidi,neuro)) # n = 501693

#############
#full sample#
#############

for( cluster in c("north", "midnorth", "midsouth", "southwest", "southeast")){

dem <- data.frame(matrix(NA, nrow=6, ncol=4))  

ids <- read.table(paste0("gxe_keepIDs_", cluster, ".txt"), header=F)

cluster_info <- ids %>%
                rename(FID = V1,
                       IID = V2) %>%
                inner_join(., df, all.x=TRUE)

female <- subset(cluster_info, cluster_info$sex=="Female")
male <- subset(cluster_info, cluster_info$sex=="Male")

dem[1,] <- cbind(dim(cluster_info), NA, NA)
dem[2,] <- cbind(table(cluster_info$sex), NA) #female, male
dem[3,] <- cbind(summary(cluster_info$age)[c(1,4,6)], NA) #min, mean, max
dem[4,] <- cbind(table(cluster_info[cluster_info$sex=="Female", 7])[2],
                 table(cluster_info[cluster_info$sex=="Male", 7])[2],
                 table(cluster_info[cluster_info$sex=="Female", 7])[1],
                 table(cluster_info[cluster_info$sex=="Male", 7])[1])

dem[5,] <- cbind(table(cluster_info[cluster_info$sex=="Female", 6])[2],
                 table(cluster_info[cluster_info$sex=="Male", 6])[2],
                 table(cluster_info[cluster_info$sex=="Female", 6])[1],
                 table(cluster_info[cluster_info$sex=="Male", 6])[1])

dem[6,] <- cbind(summary(female$NEURO)[4], 
                 dim(female[complete.cases(female$NEURO),])[1],
                 summary(male$NEURO)[4],
                 dim(male[complete.cases(male$NEURO),])[1])

write.csv(dem, paste0(cluster, "_FULL_TRAUMA_demographics.csv"), row.names=F)

}

####################
# M, F full sample #
####################

for( cluster in c("north", "midnorth", "midsouth", "southwest", "southeast")){

demf <- data.frame(matrix(NA, nrow=5, ncol=4))  
demm <- data.frame(matrix(NA, nrow=5, ncol=4))  

ids <- read.table(paste0("gxe_keepIDs_", cluster, ".txt"), header=F)

cluster_info <- ids %>%
                rename(FID = V1,
                       IID = V2) %>%
                inner_join(., df, all.x=TRUE)

female <- subset(cluster_info, cluster_info$sex=="Female")
male <- subset(cluster_info, cluster_info$sex=="Male")

demf[1,] <- cbind(dim(female), NA, NA)
demf[2,] <- cbind(summary(female$age)[c(1,4,6)], NA) #min, mean, max
demf[3,] <- cbind(table(female$CIDI)[2], table(female$CIDI)[1])
demf[4,] <- cbind(table(female$BROAD)[2], table(female$BROAD)[1])
demf[5,] <- cbind(summary(female$NEURO)[4],
                 dim(female[complete.cases(female$NEURO),])[1])

demm[1,] <- cbind(dim(male), NA, NA)
demm[2,] <- cbind(summary(male$age)[c(1,4,6)], NA) #min, mean, max
demm[3,] <- cbind(table(male$CIDI)[2], table(male$CIDI)[1])
demm[4,] <- cbind(table(male$BROAD)[2], table(male$BROAD)[1])
demm[5,] <- cbind(summary(male$NEURO)[4],
                 dim(male[complete.cases(male$NEURO),])[1])

write.csv(demf, paste0(cluster, "_FEMALE_TRAUMA_demographics.csv"), row.names=F)

write.csv(demm, paste0(cluster, "_MALE_TRAUMA_demographics.csv"), row.names=F)
}

##################
#unrelated sample#
##################

for( cluster in c("north", "midnorth", "midsouth", "southwest", "southeast")){

dem <- data.frame(matrix(NA, nrow=6, ncol=4))  

ids <- read.table(paste0("unrelated_grms/", cluster, "_unrelated.grm.id"), header=F)
                  
cluster_info <- ids %>%
                rename(FID = V1,
                       IID = V2) %>%
                inner_join(., df, all.x=TRUE)

female <- subset(cluster_info, cluster_info$sex=="Female")
male <- subset(cluster_info, cluster_info$sex=="Male")

dem[1,] <- cbind(dim(cluster_info), NA, NA)
dem[2,] <- cbind(table(cluster_info$sex), NA) #female, male
dem[3,] <- cbind(summary(cluster_info$age)[c(1,4,6)], NA) #min, mean, max
dem[4,] <- cbind(table(cluster_info[cluster_info$sex=="Female", 7])[2],
                 table(cluster_info[cluster_info$sex=="Male", 7])[2],
                 table(cluster_info[cluster_info$sex=="Female", 7])[1],
                 table(cluster_info[cluster_info$sex=="Male", 7])[1])

dem[5,] <- cbind(table(cluster_info[cluster_info$sex=="Female", 6])[2],
                 table(cluster_info[cluster_info$sex=="Male", 6])[2],
                 table(cluster_info[cluster_info$sex=="Female", 6])[1],
                 table(cluster_info[cluster_info$sex=="Male", 6])[1])

dem[6,] <- cbind(summary(female$NEURO)[4], 
                 dim(female[complete.cases(female$NEURO),])[1],
                 summary(male$NEURO)[4],
                 dim(male[complete.cases(male$NEURO),])[1])

write.csv(dem, paste0(cluster, "_UNRELATED_TRAUMA_demographics.csv"), row.names=F)

}

#########################
# M, F unrelated sample #
#########################

for( cluster in c("north", "midnorth", "midsouth", "southwest", "southeast")){

demf <- data.frame(matrix(NA, nrow=5, ncol=4))  
demm <- data.frame(matrix(NA, nrow=5, ncol=4))  

ids <- read.table(paste0("unrelated_grms/", cluster, "_unrelated.grm.id"), header=F)
                  
cluster_info <- ids %>%
                rename(FID = V1,
                       IID = V2) %>%
                inner_join(., df, all.x=TRUE)

female <- subset(cluster_info, cluster_info$sex=="Female")
male <- subset(cluster_info, cluster_info$sex=="Male")

demf[1,] <- cbind(dim(female), NA, NA)
demf[2,] <- cbind(summary(female$age)[c(1,4,6)], NA) #min, mean, max
demf[3,] <- cbind(table(female$CIDI)[2], table(female$CIDI)[1])
demf[4,] <- cbind(table(female$BROAD)[2], table(female$BROAD)[1])
demf[5,] <- cbind(summary(female$NEURO)[4],
                 dim(female[complete.cases(female$NEURO),])[1])

demm[1,] <- cbind(dim(male), NA, NA)
demm[2,] <- cbind(summary(male$age)[c(1,4,6)], NA) #min, mean, max
demm[3,] <- cbind(table(male$CIDI)[2], table(male$CIDI)[1])
demm[4,] <- cbind(table(male$BROAD)[2], table(male$BROAD)[1])
demm[5,] <- cbind(summary(male$NEURO)[4],
                 dim(male[complete.cases(male$NEURO),])[1])

write.csv(demf, paste0(cluster, "_UNRELATED_FEMALE_TRAUMA_demographics.csv"), row.names=F)

write.csv(demm, paste0(cluster, "_UNRELATED_MALE_TRAUMA_demographics.csv"), row.names=F)
}


```

# THE GENETIC COMPONENT OF TRAUMA: {.tabset}  

It is evident that many of the environmental variables we are interested in, particularly within the field of psychiatry, are heritable. This means that these variables *also* have a genetic component. The following scripts are replicated across the different DVs and traumas.  

## Heritability of Trauma  

It is important to understand how heritable these environmental variables are, I will compute the heritability of trauma as a whole, as well the sub traumas (CT,AT,CAT); 

```{r, eval = FALSE}

# I am creating .phen files for the trauma variables
# I will run a REML analysis using trauma (and sub traumas) as the DV (phenotype) to explore the proportion of variance accounted for by the GRMs (a.k.a. SNP heritability)  
# phen files need to be in the format of FID, IID, PHENO (save with col.names=F)

rm(list=ls())
library(tidyverse) 

for(pheno in c("trauma", "CT", "AT", "CAT")){
  
  # tr stands for trauma
  tr <- read.csv(paste0("../phenotypes/", pheno, "_pcs.csv"), header=T)
  # below I ensure the remaining tr df has columns FID, IID and PC1
  tr <- tr %>%
        mutate(IID = f.eid) %>%
        select(FID = f.eid, IID, PC1)
  # Saving without col names as the .phen file needs to be header-less
  write.table(tr, paste0(pheno, ".phen"), row.names=F, col.names=F, quote=F)
  
}

#trauma n = 146425
#childhood trauma n = 153650
#adult trauma n = 150939
#catastrophic trauma n = 154295

```

I also compute heritability using only unrelated participants - for this I substitute the GRM paths to that of the unrelated GRMs e.g. ../../grm/unrelated_grms/north_unrelated  

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, MAY 2021
# Eddie UKB VCA Script

#$ -N trauma_h2
#$ -cwd
#$ -pe sharedmem 10 # number of cores
#$ -l h_vmem=8G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

gcta64 --grm ../grm/full_sample_grms/analysis_sample_north --reml --pheno trauma.phen --out h2_trauma_n_v2 --thread-num 10 --qcovar ../grm/full_sample_grms/pca_full/north_q_cov --covar ../grm/full_sample_grms/pca_full/north_cov --reml-est-fix

gcta64 --grm ../grm/full_sample_grms/analysis_sample_midnorth --reml --pheno trauma.phen --out h2_trauma_mn_v2 --thread-num 10 --qcovar ../grm/full_sample_grms/pca_full/midnorth_q_cov --covar ../grm/full_sample_grms/pca_full/midnorth_cov --reml-est-fix

gcta64 --grm ../grm/full_sample_grms/analysis_sample_midsouth  --reml --pheno trauma.phen --out h2_trauma_ms_v2 --thread-num 10 --qcovar ../grm/full_sample_grms/pca_full/midsouth_q_cov --covar ../grm/full_sample_grms/pca_full/midsouth_cov --reml-est-fix

gcta64 --grm ../grm/full_sample_grms/analysis_sample_southwest --reml --pheno trauma.phen --out h2_trauma_sw_v2 --thread-num 10 --qcovar ../grm/full_sample_grms/pca_full/southwest_q_cov --covar ../grm/full_sample_grms/pca_full/southwest_cov --reml-est-fix

gcta64 --grm ../grm/full_sample_grms/analysis_sample_southeast  --reml --pheno trauma.phen --out h2_trauma_se_v2 --thread-num 10 --qcovar ../grm/full_sample_grms/pca_full/southeast_q_cov --covar ../grm/full_sample_grms/pca_full/southeast_cov --reml-est-fix

```  
```{r, eval = FALSE}

#meta-analysing cluster results and collating all information into a single file  
library(metafor)

for(depvar in c("trauma", "CT", "AT", "CAT")){
  info <- c()
  for(cluster in c("n", "mn", "ms", "sw", "se")){
    
    hsq <- read.delim(paste0("h2_", depvar, "_", cluster, "_v2.hsq"))
    hsq_info <- cbind(depvar, cluster, hsq[4,2:3], NA)
    info <- rbind(info, hsq_info)

  }
    colnames(info) <- c("depvar", "cluster", "Variance", "SE", "P-val")

    dat <- escalc(measure="RR", yi=Variance, sei=SE, data=info)
    meta <- summary(rma.uni(as.numeric(yi), as.numeric(vi), method="FE", data=dat))
    meta_info <- cbind(depvar, "meta-A", meta$beta, meta$se, meta$pval)
    colnames(meta_info) <- c("depvar", "cluster", "Variance", "SE", "P-val")
    
    h2 <- rbind(info, meta_info)
    write.csv(h2, paste0(depvar, "_h2.csv"), row.names=F)
}

# create barplots showing H2 of the different trauma variables

library(ggplot2)

df <- list.files(pattern = "*.csv") %>% 
      map_df(~read_csv(.)) %>%
      filter(cluster == "meta-A") %>%
      mutate(ymin = Variance - 1.96*SE,
             ymax = Variance + 1.96*SE)
df$depvar[df$depvar=="trauma"] <- "TRAUMA"
df$depvar <- factor(df$depvar, levels = c("TRAUMA", "CT", "AT", "CAT"))

plot <- ggplot(data = df, aes(x = depvar, y = Variance, fill = depvar)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin = ymin, ymax = ymax), width = 0.05) + 
  scale_y_continuous(limits = c(0,1), breaks = seq(0,1,by=0.1)) + 
  scale_fill_brewer("Trauma Variables", palette="Dark2") + 
  xlab("Trauma Variables") + ylab("Proportion of Variance Accounted for by Full Sample Genomic Relationship Matrix (heritability)") + 
  ggtitle("Heritability Estimates of Trauma Variables") + 
  theme_bw()

  ggsave(file="trauma_h2.png", plot=plot, width=10, height=8)
  ggsave(file="trauma_h2.svg", plot=plot, width=10, height=8)

```

![](trauma_h2.png)

## Genetic Correlation between Trauma & Depression/Neuroticism  

I will also check if our **heritable** environmental variables are genetically correlated with our DVs - this is particularly important as this will shape how we interpret the results of downstream inferential analyses.  

```{r, eval=FALSE}

#I need to collate all DVs and trauma variables into a single file 

#################################
#reading in depression variables#
#################################

broad <- read.table("../phenotypes/broad_df", header=T)
colnames(broad)[2] <- "BROAD"
broad$BROAD[broad$BROAD==TRUE] <- 1

cidi <- read.table("../phenotypes/cidi_df", header=T)
colnames(cidi)[2] <- "CIDI"
cidi$CIDI[cidi$CIDI==TRUE] <- 1

neuro <- read.table("../phenotypes/neuro_df", header=T)
colnames(neuro)[2] <- "NEURO"

#############################
#reading in trauma variables#
#############################

trauma <- read.csv("../phenotypes/trauma_pcs.csv", header=T)
trauma <- trauma[,2:3]
colnames(trauma)[2] <- "TRAUMA"

ct <- read.csv("../phenotypes/CT_pcs.csv", header=T)
ct <- ct[,2:3]
colnames(ct)[2] <- "CT"

at <- read.csv("../phenotypes/AT_pcs.csv", header=T)
at <- at[,2:3]
colnames(at)[2] <- "AT"

cat <- read.csv("../phenotypes/CAT_pcs.csv", header=T)
cat <- cat[,2:3]
colnames(cat)[2] <- "CAT"

##########################
#collate into single file#
##########################

df <- Reduce(function(x,y) merge(x=x,y=y, by="f.eid", all.x=TRUE, all.y=TRUE), list(broad, cidi, neuro, trauma, ct, at, cat))

# duplicating FID column (as FID and IIDs are identical in UKB)
df <- df[,c(1,1:8)]

#I will be multiplying the trauma column by -1, as the values all seem to be loading negatively - if this correction is not made, this would result in negative correlations!

df[,6] <- df[,6]*-1

write.table(df, "all_pheno.phen", row.names=F, quote=F, col.names=F)

```

I explore the genetic correlation using a Haseman-Elston regression analysis in GCTA. The HE regression is a moment-based method for estimating the heritability. It is computationally much more efficient but slightly less powerful than REML as the SE of the estimate from HE regression is larger than that from REML. 

I use the HE within GCTA as this facilitates bivariate analysis as in the GREML analysis, and only requires a small amount of memory (e.g. <2GB for n=120,000). The bivariate analysis includes the computation of genetic correlation rG using a leave-one-individual-out Jackknife technique.  

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, MAY 2021
# Eddie UKB VCA Script

#$ -N cidi_rg
#$ -cwd
#$ -pe sharedmem 10 # number of cores
#$ -l h_vmem=8G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

gcta64 --HEreg-bivar 2 4 --grm ../grm/full_sample_grms/analysis_sample_north --pheno all_pheno.phen --out cidi_trauma_n 
gcta64 --HEreg-bivar 2 4 --grm ../grm/full_sample_grms/analysis_sample_midnorth --pheno all_pheno.phen --out cidi_trauma_mn
gcta64 --HEreg-bivar 2 4 --grm ../grm/full_sample_grms/analysis_sample_midsouth --pheno all_pheno.phen --out cidi_trauma_ms
gcta64 --HEreg-bivar 2 4 --grm ../grm/full_sample_grms/analysis_sample_southwest --pheno all_pheno.phen --out cidi_trauma_sw
gcta64 --HEreg-bivar 2 4 --grm ../grm/full_sample_grms/analysis_sample_southeast --pheno all_pheno.phen --out cidi_trauma_se

#gcta64 --HEreg-bivar 2 5 --grm ../grm/full_sample_grms/analysis_sample_north --pheno all_pheno.phen --out cidi_CT_n
#gcta64 --HEreg-bivar 2 5 --grm ../grm/full_sample_grms/analysis_sample_midnorth --pheno all_pheno.phen --out cidi_CT_mn
#gcta64 --HEreg-bivar 2 5 --grm ../grm/full_sample_grms/analysis_sample_midsouth --pheno all_pheno.phen --out cidi_CT_ms
#gcta64 --HEreg-bivar 2 5 --grm ../grm/full_sample_grms/analysis_sample_southwest --pheno all_pheno.phen --out cidi_CT_sw
#gcta64 --HEreg-bivar 2 5 --grm ../grm/full_sample_grms/analysis_sample_southeast --pheno all_pheno.phen --out cidi_CT_se

#gcta64 --HEreg-bivar 2 6 --grm ../grm/full_sample_grms/analysis_sample_north --pheno all_pheno.phen --out cidi_AT_n
#gcta64 --HEreg-bivar 2 6 --grm ../grm/full_sample_grms/analysis_sample_midnorth --pheno all_pheno.phen --out cidi_AT_mn
#gcta64 --HEreg-bivar 2 6 --grm ../grm/full_sample_grms/analysis_sample_midsouth --pheno all_pheno.phen --out cidi_AT_ms
#gcta64 --HEreg-bivar 2 6 --grm ../grm/full_sample_grms/analysis_sample_southwest --pheno all_pheno.phen --out cidi_AT_sw
#gcta64 --HEreg-bivar 2 6 --grm ../grm/full_sample_grms/analysis_sample_southeast --pheno all_pheno.phen --out cidi_AT_se

#gcta64 --HEreg-bivar 2 7 --grm ../grm/full_sample_grms/analysis_sample_north --pheno all_pheno.phen --out cidi_CAT_n
#gcta64 --HEreg-bivar 2 7 --grm ../grm/full_sample_grms/analysis_sample_midnorth --pheno all_pheno.phen --out cidi_CAT_mn
#gcta64 --HEreg-bivar 2 7 --grm ../grm/full_sample_grms/analysis_sample_midsouth --pheno all_pheno.phen --out cidi_CAT_ms
#gcta64 --HEreg-bivar 2 7 --grm ../grm/full_sample_grms/analysis_sample_southwest --pheno all_pheno.phen --out cidi_CAT_sw
#gcta64 --HEreg-bivar 2 7 --grm ../grm/full_sample_grms/analysis_sample_southeast --pheno all_pheno.phen --out cidi_CAT_se

```
```{r, eval = FALSE}

library(metafor)

# meta-analysing cluster results and collating all information into a single file

rm(list=ls())

for(depvar in c("cidi", "broad", "neuro")){
  
  for(trauma in c("trauma", "CT", "AT", "CAT")){
    rg <- c()
    
    for(cluster in c("n", "mn", "ms", "sw", "se")){
      
      df <- read.table(paste0(depvar, "_", trauma, "_", cluster, ".HEreg"), header = T, skip = 2, fill = TRUE)
      df <- df %>%
            select(Estimate, SE_Jackknife)
      df <- cbind(depvar, trauma, cluster, df[7,], NA)
      colnames(df) <- c("depvar", "trauma", "cluster", "Estimate", "SE", "P-val")
      rg <- rbind(rg, df)
    }
    
      dat <- escalc(measure="RR", yi=Estimate, sei=SE, data=rg)
      meta <- summary(rma.uni(as.numeric(yi), as.numeric(vi), method="FE", data=dat))
      meta_info <- cbind(depvar, trauma, "meta-A", meta$beta, meta$se, meta$pval)
      colnames(meta_info) <- c("depvar", "trauma", "cluster", "Estimate", "SE", "P-val")
      rg <- rbind(rg, meta_info)
      
      write.csv(rg, paste0(depvar, "_", trauma, "_rg.csv"), row.names=F)
      
    }}

# create barplots showing genetic correlations between different DVs and trauma variables

library(ggplot2)

df <- list.files(pattern = "*.csv") %>% 
      map_df(~read_csv(.)) %>%
      filter(cluster == "meta-A") %>%
      mutate(ymin = Estimate - 1.96*SE,
             ymax = Estimate + 1.96*SE)
df$trauma[df$trauma=="trauma"] <- "TRAUMA"
df$trauma <- factor(df$trauma, levels = c("TRAUMA", "CT", "AT", "CAT"))
df$depvar <- factor(df$depvar, levels = c("cidi", "broad", "neuro"))

plot <- ggplot(data = df, aes(x = trauma, y = Estimate, fill = trauma)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin = ymin, ymax = ymax), width = 0.05) + 
  scale_y_continuous(limits = c(0,1), breaks = seq(0,1,by=0.1)) + 
  scale_fill_brewer("Trauma Variables", palette="Dark2") + 
  facet_wrap(~depvar) + 
  xlab("Trauma Variables") + ylab("Genetic Correlation") + 
  ggtitle("Genetic Correlation Between Dependent & Trauma Variables") + 
  theme_bw()

  ggsave(file="genetic_correlations.png", plot=plot, width=10, height=8)
  ggsave(file="genetic_correlations.svg", plot=plot, width=10, height=8)

``` 

![](genetic_correlations.png) 







# GENOMIC RELATIONSHIP MATRICES: {.tabset}     
GRMs will fitted as a random effect within a mixed linear model framework - variance accounted for by the GRM will be a measure of heritability  
## FULL SAMPLE GRMs  

1. The first thing we need to do is create separate binary plink files for participants in the different geographical clusters

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, April 2021
# Eddie UKB GRM Script

#$ -N grm_bfile_plink
#$ -cwd
#$ -pe sharedmem 5 # number of cores
#$ -l h_vmem=20G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/plink/1.90b4 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

plink --bfile UKBgenotype --keep gxe_keepIDs_north.txt --make-bed --out analysis_sample_north
plink --bfile UKBgenotype --keep gxe_keepIDs_midnorth.txt --make-bed --out analysis_sample_midnorth
plink --bfile UKBgenotype --keep gxe_keepIDs_midsouth.txt --make-bed --out analysis_sample_midsouth
plink --bfile UKBgenotype --keep gxe_keepIDs_southwest.txt --make-bed --out analysis_sample_southwest
plink --bfile UKBgenotype --keep gxe_keepIDs_southeast.txt --make-bed --out analysis_sample_southeast

```
2. Using the cluster binary plink files, I will create GRMs using GCTA  

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, April 2021
# Eddie UKB GRM Script

#$ -N cluster_grm
#$ -cwd
#$ -pe sharedmem 5 # number of cores
#$ -l h_vmem=8G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

gcta64 --bfile analysis_sample_north --make-grm --out analysis_sample_north --thread-num 5

gcta64 --bfile analysis_sample_midnorth --make-grm --out analysis_sample_midnorth --thread-num 5

gcta64 --bfile analysis_sample_midsouth --make-grm --out analysis_sample_midsouth --thread-num 5

gcta64 --bfile analysis_sample_southeast --make-grm --out analysis_sample_southeast --thread-num 5

gcta64 --bfile analysis_sample_southwest --make-grm --out analysis_sample_southwest --thread-num 5

```
## UNRELATED SAMPLE GRMs  

We can extract unrelated individuals from our full GRMs - this is a fairly quick process that does not use a lot of memory. It might be better to compute h2 using unrelated GRMs as this will ensure heritability estimates are not biased upwards due to present relatives and thus, shared environments.  

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, April 2021
# Eddie UKB GRM Script

#$ -N grm_unrelated 
#$ -cwd
#$ -pe sharedmem 1 # number of cores
#$ -l h_vmem=8G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

gcta64 --grm ../analysis_sample_north --grm-cutoff 0.025 --make-grm --thread-num 1 --out north_unrelated

gcta64 --grm ../analysis_sample_midnorth --grm-cutoff 0.025 --make-grm --thread-num 1 --out midnorth_unrelated

gcta64 --grm ../analysis_sample_midsouth --grm-cutoff 0.025 --make-grm --thread-num 1 --out midsouth_unrelated

gcta64 --grm ../analysis_sample_southwest --grm-cutoff 0.025 --make-grm --thread-num 1 --out southwest_unrelated

gcta64 --grm ../analysis_sample_southeast --grm-cutoff 0.025 --make-grm --thread-num 1 --out southeast_unrelated

```
## KINSHIP MATRICES  

One other form of relatedness matrix is a kinship matrix, where individual who have a relatedness value (G) of less than <0.05 are limited to 0, and actual relatives keep their realised relatedness value. Usually, you would fit the K-matrix alongside the GRM (Xia et al., 2016). However, this will likely not make a huge impact on our results as we do not have a lot of related individuals!  

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, April 2021
# Eddie UKB GRM Script

#$ -N cluster_kinship_matrix
#$ -cwd
#$ -pe sharedmem 1 # number of cores
#$ -l h_vmem=8G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

gcta64 --grm ../analysis_sample_north --make-bK 0.05 --out north_bK
gcta64 --grm ../analysis_sample_midnorth --make-bK 0.05 --out midnorth_bK
gcta64 --grm ../analysis_sample_midsouth --make-bK 0.05 --out midsouth_bK
gcta64 --grm ../analysis_sample_southwest --make-bK 0.05 --out southwest_bK
gcta64 --grm ../analysis_sample_southeast --make-bK 0.05 --out southeast_bK

```
## Reading GRMs  

Binary format GRMs are created which are useful as does not take up a lot of space! But, can be difficult to read into programming software. However, the data from the binary files can be extracted and a list can be created entailing the diagonals (individual genomic relationships with themselves), offdiagonals (individual genomic relationships with others in the matrix), participant IDs and the number of SNPs shared/used to calculate genomic relationships.

```{r}
# script obtained from Carmen Amador 
# this function creates a list of vectors including the diagonal, offdiagonal, ps ID and No. SNPs shared for each pair in the matrix

ReadGRMBin=function(prefix,AllN=F,size=4){
		
		sum_i=function(i){
		 return(sum(1:i))
		}
		
		BinFileName=paste(prefix,".grm.bin",sep="")
		NFileName=paste(prefix,".grm.N.bin",sep="")
		IDFileName=paste(prefix,".grm.id",sep="")
		id=read.table(IDFileName)
		n=dim(id)[1]
		BinFile=file(BinFileName,"rb");
		grm=readBin(BinFile,n=n*(n+1)/2,what=numeric(0),size=size)
		NFile=file(NFileName,"rb");
		if(AllN==T){
			N=readBin(NFile,n=n*(n+1)/2,what=numeric(0),size=size)
		}
		else	N=readBin(NFile,n=1,what=numeric(0),size=size)
		i=sapply(1:n,sum_i)
		return(list(diag=grm[i],off=grm[-i],id=id,N=N))
}

```

## GRM Relative Count  

We want to count the number of people who fall into different cryptic relatedness bins  

```{r, eval=FALSE}

for(cluster in c("north", "midnorth", "midsouth", "southwest", "southeast")){
  
  cluster <- ReadGRMBin(paste0("analysis_sample_", cluster))
  #creating different relative bins
  first_degree <- cluster$off[cluster$off>=0.3 & cluster$off<0.6] 
second_degree <- cluster$off[cluster$off>=0.2 & cluster$off<0.3] 
third_degree <- cluster$off[cluster$off>=0.05 & cluster$off<0.2] 

length(first_degree)
length(second_degree)
length(third_degree)


  cr <- matrix(NA, nrow=1, ncol=3)
  cr[1,1] <- length(first_degree)
  cr[1,2] <- length(second_degree)
  cr[1,3] <- length(third_degree)
  
  write.csv(cr, paste0("cluster_relative_sample_", cluster, ".csv"))
  rm(cluster)
  
}

#information on relative counts within each cluster can be found in the supplementary materials!
```


## Computing GRM Principle Components

We only need to do this for the realised full sample genomic relatedness matrices, these principal components will be used as covariates in downstream analyses  

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, May 2021
# Eddie UKB GRM Script

#$ -N fullGRM_pca_analysis
#$ -cwd
#$ -pe sharedmem 12 # number of cores
#$ -l h_vmem=16G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

#full sample

gcta64 --grm ../analysis_sample_midnorth --pca 15 --out midnorth_pcs --thread-num 4
gcta64 --grm ../analysis_sample_midsouth --pca 15 --out midsouth_pcs --thread-num 4
gcta64 --grm ../analysis_sample_southwest --pca 15 --out southwest_pcs --thread-num 4
gcta64 --grm ../analysis_sample_southeast --pca 15 --out southeast_pcs --thread-num 4

```

# ENVIRONMENTAL RELATIONSHIP MATRICES:  

ERMs will be fitted as random effects within a mixed linear model framework. The ERMs represent trauma experience similarity between our participants. Variance accounted for by the ERM can be interpreted as the variance accounted for by trauma effects.  

Will be making use of the software OSCA https://cnsgenomics.com/software/osca/#DataManagement which is actually a software which can create relationship matrices using methylation or other omics data. However, here I will be using the trauma principal components instead of omics data.  

## Which OSCA Algorithm Should We Be Using? {.tabset}  

There are different algorithms when creating the environmental relationship matrices. Details for each of the algorithms can be found in the paper (Zhang et al., 2019) as well as the OSCA website https://cnsgenomics.com/software/osca/#Overview.  

As this software is primarily created with DNA methylation data in mind, and not necessarily for the data type we have, we need to make sure the algorithms are not crucially affecting the results. Currently from the formula and brief explanations provided it seems the algorithms should not have a huge impact on the interpretation of results. However, I will explore potential differences that may arise from the different algorithms to ensure that this does not limit our interpretation of results.   

Essentially the different algorithms 1:3 can be summarised as:  

Algorithm 1.Matrix of standardized DNAm measures of all probes  

Algorithm 2.This model implicitly assumes that the probes of smaller variance in DNAm level (unstandardized) tend to have larger effects on the phenotype (strictly speaking, stronger associations with the phenotype) and that there is no relationship between the proportion of trait variance captured by a probe and the variance of the probe.  

Algorithm 3.We implicitly assume that there is no relationship between the probe effect on the trait and the variance of the probe but the proportion of trait variance associated with a probe increases as the variance of the probe increases.  

Based on the brief explanations obtained from the paper and the website, it seems evident that algorithm 2 is definitely not suitable for our data as there is no evidence of less experienced traumas having a greater impact.  

### Algorithm 1  

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, June 2021
# Eddie UKB ERM Script

#$ -N erm_1
#$ -cwd
#$ -pe sharedmem 5 # number of cores
#$ -l h_vmem=8G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line


# CREATING ORM FILES 

../osca_Linux --befile ../trauma_north --make-orm --out trauma_north --thread-num 5

../osca_Linux --befile ../trauma_midnorth --make-orm --out trauma_midnorth --thread-num 5

../osca_Linux --befile ../trauma_midsouth --make-orm --out trauma_midsouth --thread-num 5

../osca_Linux --befile ../trauma_southwest --make-orm --out trauma_southwest --thread-num 5

../osca_Linux --befile ../trauma_southeast --make-orm --out trauma_southeast --thread-num 5

```
### Algorithm 3  

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, June 2021
# Eddie UKB ERM Script

#$ -N erm_3
#$ -cwd
#$ -pe sharedmem 5 # number of cores
#$ -l h_vmem=8G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line


# CREATING ORM FILES USING ALGORITHM 3 

../osca_Linux --befile ../trauma_north --make-orm --orm-alg 3 --out trauma_north3 --thread-num 5

../osca_Linux --befile ../trauma_midnorth --make-orm --orm-alg 3 --out trauma_midnorth3 --thread-num 5

../osca_Linux --befile ../trauma_midsouth --make-orm --orm-alg 3 --out trauma_midsouth3 --thread-num 5

../osca_Linux --befile ../trauma_southwest --make-orm --orm-alg 3 --out trauma_southwest3 --thread-num 5

../osca_Linux --befile ../trauma_southeast --make-orm --orm-alg 3 --out trauma_southeast3 --thread-num 5

```

### REML Analysis Comparisons  

More information on REML and mixed linear models can be found in the sections below - here the most important thing to note if there aren't vast differences between the results obtained from ERMs created using the different algorithms.  

For each MLM run using REML, I will be fitting the ERM (whole sample) of each cluster as a random effect. I will also be including AGE, SEX, GENOTYPING ARRAY and 10 genetic principal components (PCs) from the realised GRM (whole sample) as covariates.  

I use a semi-arbitrary value 0.16 as the prevalence for Broad Dep and CIDI Dep DVs - this a value that falls within the range of reported prevalence rates for depression within the literature (although it is important to note that this is not the same prevalence rate as seen in our sample - results do not change much)!  

The 4 main MLMs explored are:    

$$ DV \sim Covariates + GRM $$  
$$ DV \sim Covariates + ERM $$  
$$ DV \sim Covariates + GRM + ERM $$  
$$ DV \sim Covariates + GRM + ERM + GRMxERM $$  

The following shell scrip is can be re-run using the other available DVs. However, as this is merely to identify which algorithm to use going forward, I limit the analyses to CIDI depression as the DV.  

1. Running MLM with GRM as a random effect  

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, MAY 2021
# Eddie UKB VCA Script

#$ -N cidi_h2_0.16
#$ -cwd
#$ -pe sharedmem 8 # number of cores
#$ -l h_vmem=16G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

gcta64 --grm ../../full_sample_grms/analysis_sample_north --reml --pheno ../cidi.phen --out h2_cidi_n_0.16 --thread-num 8 --prevalence 0.16 --qcovar ../../full_sample_grms/pca_full/north_q_cov --covar ../../full_sample_grms/pca_full/north_cov --reml-est-fix --reml-priors 0 1

gcta64 --grm ../../full_sample_grms/analysis_sample_midnorth --reml --pheno ../cidi.phen --out h2_cidi_mn_0.16 --thread-num 8 --prevalence 0.16 --qcovar ../../full_sample_grms/pca_full/midnorth_q_cov --covar ../../full_sample_grms/pca_full/midnorth_cov --reml-est-fix --reml-priors 0 1 

gcta64 --grm ../../full_sample_grms/analysis_sample_midsouth  --reml --pheno ../cidi.phen --out h2_cidi_ms_0.16 --thread-num 8 --prevalence 0.16 --qcovar ../../full_sample_grms/pca_full/midsouth_q_cov --covar ../../full_sample_grms/pca_full/midsouth_cov --reml-est-fix --reml-priors 0 1 

gcta64 --grm ../../full_sample_grms/analysis_sample_southwest --reml --pheno ../cidi.phen --out h2_cidi_sw_0.16 --thread-num 8 --prevalence 0.16 --qcovar ../../full_sample_grms/pca_full/southwest_q_cov --covar ../../full_sample_grms/pca_full/southwest_cov --reml-est-fix --reml-priors 0 1 

gcta64 --grm ../../full_sample_grms/analysis_sample_southeast  --reml --pheno ../cidi.phen --out h2_cidi_se_0.16 --thread-num 8 --prevalence 0.16 --qcovar ../../full_sample_grms/pca_full/southeast_q_cov --covar ../../full_sample_grms/pca_full/southeast_cov --reml-est-fix --reml-priors 0 1 

```
2. Running MLM with ERM as a random effect. Remember this needs to be re-run using ERMs created with algorithm 3!    

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, MAY 2021
# Eddie UKB VCA Script

#$ -N cidi_erm1_reml
#$ -cwd
#$ -pe sharedmem 10 # number of cores
#$ -l h_vmem=16G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

gcta64 --grm ../../erm_full_alg1/trauma_north --reml --pheno ../cidi.phen --out h2_cidi_erm1_n --prevalence 0.16 --thread-num 10  --qcovar ../../../grm/full_sample_grms/pca_full/north_q_cov --covar ../../../grm/full_sample_grms/pca_full/north_cov --reml-est-fix  

gcta64 --grm ../../erm_full_alg1/trauma_midnorth --reml --pheno ../cidi.phen --out h2_cidi_erm1_mn --prevalence 0.16 --thread-num 10 --qcovar ../../../grm/full_sample_grms/pca_full/midnorth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midnorth_cov --reml-est-fix

gcta64 --grm ../../erm_full_alg1/trauma_midsouth --reml --pheno ../cidi.phen --out h2_cidi_erm1_ms --prevalence 0.16 --thread-num 10 --qcovar ../../../grm/full_sample_grms/pca_full/midsouth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midsouth_cov --reml-est-fix

gcta64 --grm ../../erm_full_alg1/trauma_southwest --reml --pheno ../cidi.phen --out h2_cidi_erm1_sw --prevalence 0.16 --thread-num 10 --qcovar ../../../grm/full_sample_grms/pca_full/southwest_q_cov --covar ../../../grm/full_sample_grms/pca_full/southwest_cov --reml-est-fix

gcta64 --grm ../../erm_full_alg1/trauma_southeast --reml --pheno ../cidi.phen --out h2_cidi_erm1_se --prevalence 0.16 --thread-num 10 --qcovar ../../../grm/full_sample_grms/pca_full/southeast_q_cov --covar ../../../grm/full_sample_grms/pca_full/southeast_cov --reml-est-fix

```  
3. Running MLM with GRM + ERM as a random effect. Remember this needs to be re-run using ERMs created with algorithm 3!    

A text file needs detailing the location of each relationship matrix for each cluster needs to be created!   

**E.G** mgrm_G+E_north.txt  

```
../../erm_full_alg1/trauma_north
../../../grm/full_sample_grms/analysis_sample_north

```
```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, MAY 2021
# Eddie UKB VCA Script

#$ -N cidi_g+e1_h2
#$ -cwd
#$ -pe sharedmem 10 # number of cores
#$ -l h_vmem=16G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

gcta64 --mgrm mgrm_G+E_north.txt --reml --pheno ../cidi.phen --out h2_cidi_G+E1_n --thread-num 10 --prevalence 0.16 --qcovar ../../../grm/full_sample_grms/pca_full/north_q_cov --covar ../../../grm/full_sample_grms/pca_full/north_cov --reml-lrt 1 --reml-est-fix  

gcta64 --mgrm mgrm_G+E_midnorth.txt --reml --pheno ../cidi.phen --out h2_cidi_G+E1_mn --thread-num 10 --prevalence 0.16 --qcovar ../../../grm/full_sample_grms/pca_full/midnorth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midnorth_cov --reml-lrt 1 --reml-est-fix

gcta64 --mgrm mgrm_G+E_midsouth.txt  --reml --pheno ../cidi.phen --out h2_cidi_G+E1_ms --thread-num 10 --prevalence 0.16 --qcovar ../../../grm/full_sample_grms/pca_full/midsouth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midsouth_cov --reml-lrt 1 --reml-est-fix

gcta64 --mgrm mgrm_G+E_southwest.txt  --reml --pheno ../cidi.phen --out h2_cidi_G+E1_sw --thread-num 10 --prevalence 0.16 --qcovar ../../../grm/full_sample_grms/pca_full/southwest_q_cov --covar ../../../grm/full_sample_grms/pca_full/southwest_cov --reml-lrt 1 --reml-est-fix

gcta64 --mgrm mgrm_G+E_southeast.txt   --reml --pheno ../cidi.phen --out h2_cidi_G+E1_se --thread-num 10 --prevalence 0.16 --qcovar ../../../grm/full_sample_grms/pca_full/southeast_q_cov --covar ../../../grm/full_sample_grms/pca_full/southeast_cov --reml-lrt 1 --reml-est-fix

```
4. Running MLM with GRM, ERM, GRMxERM as random effects. Remember this needs to be re-run using ERMs created with algorithm 3! This analysis consists of 3 steps, first generating the interaction matrix, then creating the relationship matrix location text files, followed by running the actual MLM analysis.  

Here we will use the hadamard product of the GRM and ERM (more information on how we obtain the interaction matrix can be found detailed below)  
A shell script (code provided by Carmen Amador) to specify which matrices to use for the final interaction matrices needs to be created for each cluster  

**E.G** RunHadamardP_north.sh  

```
NIND=24287
G1=$'analysis_sample_north'
G2=$'trauma_north'
Out=$'GxTRAUMA_north'

./HadamardP $NIND $G1 $G2 $Out > $Out.log

## WARNING
## For Nind>>> the grm.N.bin file might be problematic, copy from G or E matrix:
## cp $G1.grm.N.bin GxE_$Out.grm.N.bin

```
Where NIND is the sample size of grm.id  
G1 is the first matrix  
G2 is the second matrix  
Out is the name of the interaction matrix  

To create the interaction matrices, I run the shell script which uses an executable file provided by Carmen Amador (more information can be found below!)
We need to copy the GRM.grm.N.bin files and save as GxTrauma.grm.N.bin files - following warning/advice provided by Carmen

```
cp analysis_sample_north.grm.N.bin GxTRAUMA_north.grm.N.bin

cp analysis_sample_midnorth.grm.N.bin GxTRAUMA_midnorth.grm.N.bin

cp analysis_sample_midsouth.grm.N.bin GxTRAUMA_midsouth.grm.N.bin

cp analysis_sample_southwest.grm.N.bin GxTRAUMA_southwest.grm.N.bin

cp analysis_sample_southeast.grm.N.bin GxTRAUMA_southeast.grm.N.bin

```
A text file needs detailing the location of each relationship matrix for each cluster needs to be created!    

**E.G** mgrm_GxE_north.txt  

```
../alg1_files/analysis_sample_north

../alg1_files/trauma_north

../alg1_files/GxTRAUMA_north

```
```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, MAY 2021
# Eddie UKB VCA Script

#$ -N cidi_gxe1_h2
#$ -cwd
#$ -pe sharedmem 10 # number of cores
#$ -l h_vmem=16G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

gcta64 --mgrm mgrm_GxE_north.txt --reml --pheno cidi.phen --out h2_cidi_GxE1_n --thread-num 10 --prevalence 0.16 --qcovar ../../../grm/full_sample_grms/pca_full/north_q_cov --covar ../../../grm/full_sample_grms/pca_full/north_cov --reml-lrt 3 --reml-est-fix  

gcta64 --mgrm mgrm_GxE_midnorth.txt --reml --pheno cidi.phen --out h2_cidi_GxE1_mn --thread-num 10 --prevalence 0.16 --qcovar ../../../grm/full_sample_grms/pca_full/midnorth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midnorth_cov --reml-lrt 3 --reml-est-fix

gcta64 --mgrm mgrm_GxE_midsouth.txt  --reml --pheno cidi.phen --out h2_cidi_GxE1_ms --thread-num 10 --prevalence 0.16 --qcovar ../../../grm/full_sample_grms/pca_full/midsouth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midsouth_cov --reml-lrt 3 --reml-est-fix

gcta64 --mgrm mgrm_GxE_southwest.txt  --reml --pheno cidi.phen --out h2_cidi_GxE1_sw --thread-num 10 --prevalence 0.16 --qcovar ../../../grm/full_sample_grms/pca_full/southwest_q_cov --covar ../../../grm/full_sample_grms/pca_full/southwest_cov --reml-lrt 3 --reml-est-fix

gcta64 --mgrm mgrm_GxE_southeast.txt   --reml --pheno cidi.phen --out h2_cidi_GxE1_se --thread-num 10 --prevalence 0.16 --qcovar ../../../grm/full_sample_grms/pca_full/southeast_q_cov --covar ../../../grm/full_sample_grms/pca_full/southeast_cov --reml-lrt 3 --reml-est-fix

```

```{r, eval=FALSE}
# SCRIPT TO COLLATE REML RESULTS  

################################
##             GRM            ##
################################

rm(list=ls())
ov <- as.data.frame(matrix(NA, nrow=8, ncol=1)) #creating a dataframe ov, overview
ov[,1] <- c("VG", "VE", "VP", "H2", "LogL", "LogL0", "LRT", "P_Val")

  for(prefix in c("n", "mn", "ms", "sw", "se")){ #clusters
    hsq <- read.delim(paste0("h2_cidi_", prefix, "_0.16.hsq"))
    hsq_info <- hsq[c(1:3, 7:10,12),2:3] #VG,VE,VP,H2,LRT, P-VAL
    ov <- cbind(ov, hsq_info)
  }
write.csv(ov, "cidi_grm_0.16_VCA_info.csv", row.names=F, quote=F)

################################
##             ERM            ##
################################

rm(list=ls())
ov <- as.data.frame(matrix(NA, nrow=8, ncol=1)) #creating a dataframe ov, overview
ov[,1] <- c("VG", "VE", "VP", "H2", "logL", "logL0", "LRT", "P_Val")

  for(prefix in c("n", "mn", "ms", "sw", "se")){ #clusters
    hsq <- read.delim(paste0("h2_cidi_erm1_", prefix, ".hsq"))
    hsq_info <- hsq[c(1:3,7:10,12),2:3] #VG,VE,VP,H2,LRT, P-VAL
    ov <- cbind(ov, hsq_info)
  }
write.csv(ov, "cidi_erm1_VCA_info.csv", row.names=F, quote=F)

################################
##         GRM + ERM          ##
################################

rm(list=ls())
ov <- as.data.frame(matrix(NA, nrow=11, ncol=1)) #creating a dataframe ov, overview
ov[,1] <- c("VG1", "VG2", "VE", "VP", "H2_1", "H2_2", "H2", "logL", "logL0", "LRT", "P_Val")

  for(prefix in c("n", "mn", "ms", "sw", "se")){ #clusters
    hsq <- read.delim(paste0("h2_cidi_G+E1_", prefix, ".hsq"))
    hsq_info <- hsq[c(1:4, 10:15,17),2:3] #VG,VE,VP,H2,LRT, P-VAL
    ov <- cbind(ov, hsq_info)
  }
write.csv(ov, "cidi_G+E1_VCA_info.csv", row.names=F, quote=F)

################################
##   GRM + ERM + GRMxERM      ##
################################

rm(list=ls())
ov <- as.data.frame(matrix(NA, nrow=13, ncol=1)) #creating a dataframe ov, overview
ov[,1] <- c("VG1", "VG2", "VG3", "VE", "VP", "H2_1", "H2_2", "H2_3", "H2_sum", "logL", "logL0", "LRT", "P_Val")

  for(prefix in c("n", "mn", "ms", "sw", "se")){ #clusters
    hsq <- read.delim(paste0("h2_cidi_GxE1_", prefix, ".hsq"))
    hsq_info <- hsq[c(1:5, 12:18,20),2:3] #VG,VE,VP,H2,LRT, P-VAL
    ov <- cbind(ov, hsq_info)
  }
write.csv(ov, "cidi_GxE1_VCA_info.csv", row.names=F, quote=F)

```

### Matrix Comparisons  

REML findings were actually pretty much the same (which is good! but doesnt really point to a specific algorithm to use) - I also plot GRM and ERM offdiagonals to aid visualisation of the data and selection of OSCA algorithm to use.  

```{r, eval=FALSE}

# create a function to read in the GRM and ERM files, this function is specified above in the GRM section
# the ERM file extension names were converted from e.g. orm.bin to grm.bin, so the function can be used to read the ERMs as well!
# I am comparing the OFFDIAGONALS of the GRM and ERMs


#################
#Alg1ERM vs GRM #
#################

for (cluster in c("north", "midnorth", "midsouth", "southwest", "southeast")){
  
grm <- ReadGRMBin(paste0("../../grm/full_sample_grms/analysis_sample_", cluster))

erm <- ReadGRMBin(paste0("../erm_full_alg1/trauma_", cluster))

png(filename = paste0(cluster,"_alg1_grm_erm_comp.png"))

plot(grm$off, erm$off)

dev.off()

cor.test(grm$off, erm$off)

}

#################
#Alg3ERM vs GRM #
#################

for (cluster in c("north", "midnorth", "midsouth", "southwest", "southeast")){
  
  grm <- ReadGRMBin(paste0("../../grm/full_sample_grms/analysis_sample_", cluster))
  
  erm <- ReadGRMBin(paste0("../erm_full_alg3/trauma_", cluster, "3"))
  
  png(filename = paste0(cluster,"_alg3_grm_erm_comp.png"))
  
  plot(grm$off, erm$off)

  dev.off()
  cor.test(grm$off, erm$off)
}

```

![](ERM_v_GRM_differentALGS.png) 
```{r, eval=FALSE}

#################
#Alg1GxE vs GRM #
#################

for (cluster in c("north", "midnorth", "midsouth", "southwest", "southeast")){
  
  int <- ReadGRMBin(paste0("../reml_GxE/alg1_files/GxTRAUMA_", cluster))
  
  grm <- ReadGRMBin(paste0("../reml_GxE/alg1_files/analysis_sample_", cluster))
  
  png(filename = paste0(cluster,"_int_grm_alg1_comp.png"))
  
  plot(int$off, grm$off)

  dev.off()
  
  print(cor.test(int$off, grm$off))
}

#################
#Alg3GxE vs GRM #
#################

for (cluster in c("north", "midnorth", "midsouth", "southwest", "southeast")){
  
  int <- ReadGRMBin(paste0("../reml_GxE/alg3_files/GxTRAUMA3_", cluster))
  
  grm <- ReadGRMBin(paste0("../reml_GxE/alg3_files/analysis_sample_", cluster))
  
  png(filename = paste0(cluster,"_int_grm_alg3_comp.png"))
  
  plot(int$off, grm$off)

  dev.off()
  
  print(cor.test(int$off, grm$off))
}

```

![](intERM_v_GRM_differentALGS.png) 


## Computed ERMs {.tabset}  
### ERM Trauma (16 Principal Components)  

I first need to convert the .txt file with FID, IID and trauma PC data into a bod file format so it can be used by OSCA; this will be conducted using all trauma PCs and also sub trauma PCs separately (scripts for subtraumas have been separated)  

```
#I am currently using a Linux machine, so will make use of the Linux executable of osca

wget https://cnsgenomics.com/software/osca/download/osca_Linux.zip
unzip osca_Linux.zip.

#I also need to make sure my software is executable
chmod u+x osca_Linux

./osca_Linux --efile trauma_north_profile.txt --make-bod --out trauma_north

./osca_Linux --efile trauma_midnorth_profile.txt --make-bod --out trauma_midnorth

./osca_Linux --efile trauma_midsouth_profile.txt --make-bod --out trauma_midsouth

./osca_Linux --efile trauma_southwest_profile.txt --make-bod --out trauma_southwest

./osca_Linux --efile trauma_southeast_profile.txt --make-bod --out trauma_southeast

```  
Then I compute the ERM using OSCA  

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, June 2021
# Eddie UKB ERM Script

#$ -N erm_1
#$ -cwd
#$ -pe sharedmem 5 # number of cores
#$ -l h_vmem=8G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line


# CREATING ORM FILES 

../osca_Linux --befile ../trauma_north --make-orm --out trauma_north --thread-num 5

../osca_Linux --befile ../trauma_midnorth --make-orm --out trauma_midnorth --thread-num 5

../osca_Linux --befile ../trauma_midsouth --make-orm --out trauma_midsouth --thread-num 5

../osca_Linux --befile ../trauma_southwest --make-orm --out trauma_southwest --thread-num 5

../osca_Linux --befile ../trauma_southeast --make-orm --out trauma_southeast --thread-num 5

```

### ERM Trauma (Principal Components Residualised)   

One issue that can occur within our analyses is that the proportion of phenotypic variance captured by the GRMs can actually be capturing environmental variance. What do we mean by environmental variance? Here we are NOT talking about gene-environment correlations. An example can be: you have a family who were in an accident that was purely caused by external factors. The family members will have higher values of trauma (and trauma similarity), and as they are a family they have higher genetic similarity - thus, this effect may be picked up as heritability when in actual fact it is shared environmental variance!  

Another issue is that there may be gene-environment correlation effects between the heritable environmental variable and our outcomes. This also needs to be controlled for as this can have an impact on results.  

Exploring analyses in only the unrelated sample can also work around the shared environmental variance issue - which I will go on to do for the majority of the upcoming analyses! Removing the effect of genetics from the environmental variables can also help combat these issues to an extent!  

$$ PC1:16 \sim GRM + AGE + SEX + GRM PCs1:15 $$
So I can obtain the residuals from this mixed linear model and build an ERM using the residuals!  

First we need to create separate .phen files for each PC  

```{r, eval=FALSE}
trauma_pcs <- read.csv("../../phenotypes/trauma_pcs.csv")
trauma_pcs <- trauma_pcs[,-1] #removing rownumber file 

for (col in c(2:17)){
  write.table(trauma_pcs[,c(1,1,col)], paste0("trauma_", names(trauma_pcs)[col], ".phen"), col.names=F, quote=F, row.names=F)
}

```

I now need to run reml MLM to obtain the residuals - remember we have GRMs in 5 clusters, so 16 PCs x 5 GRM clusters  

Using the --reml-pred-rand command, the random effects are predicted using the BLUP method (best linear unbiased prediction). The output includes a indi.blp file, which consists of 6 columns, the first 2 being FID and IID and the final column being the residual effects.  

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, MAY 2021
# Eddie UKB VCA Script

#$ -N traumaPC1_residuals
#$ -cwd
#$ -pe sharedmem 20 # number of cores
#$ -l h_vmem=32G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m be ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

for i in `seq 1 16`
do
gcta64 --grm ../../grm/full_sample_grms/analysis_sample_north --reml --phen trauma_PC"$i".phen --out traumaPC"$i"_north_resid --reml-pred-rand --thread-num 10 --qcovar ../../grm/full_sample_grms/pca_full/north_q_cov --covar ../../grm/full_sample_grms/pca_full/north_cov --reml-est-fix
done

```
Residuals are collated into a single file for each cluster.  

```{r, eval=FALSE}


for (cluster in c("north", "midnorth", "midsouth", "southwest", "southeast")){
  
resid <- c() #creating an empty file to store the PC1:16 residuals i.e. collector

check <- read.delim(paste0("traumaPC1_", cluster, "_resid.indi.blp"), header=F) # this is my FID, IID check. I need to make sure that the residuals pasted next to each other belong to the same participant

for(pc in c(1:16)){

   pcs <- read.delim(paste0("traumaPC", pc, "_", cluster, "_resid.indi.blp"), header=F)
   
   pcs <- pcs[,c(1:2,6)] #extracting FID, IID, and residual effect column
   
   resid <- cbind(resid, pcs[,3]) #binding the PC1:16 residual effects
   
   print(identical(pcs[,1], check[,1])) #double checking the identities of each row are the same in our files
   print(identical(pcs[,2], check[,2]))

}

ids_resid <- cbind(check[,c(1:2)], resid) #combinding the residual effects with their participant IDs
df_name <- paste0(cluster, "_traumaPC_resid.txt") # unique name to this ID+residual file to be saved

write.table(ids_resid, file=df_name, row.names=F, quote=F)

}

```

I also want to ensure that residualised PCs are associated with our phenotypes of interest  

```{r, eval=FALSE}

rm(list=ls())

broad <- read.table("broad_df", header=T) # n = 486165
colnames(broad)[2] <- "broad"

cidi <- read.table("cidi_df", header=T) # n = 128927
colnames(cidi)[2] <- "cidi"

neuro <- read.table("neuro_df", header=T) # n = 401663
colnames(neuro)[2] <- "neuro"

cov <- read.table("covariates", header=T)
cov <- cov[,c(1:2,4)] #keeping only age and sex
colnames(cov)[1] <- "f.eid"

north <- read.table("../erm/north_traumaPC_resid.txt", header=T)
midnorth <- read.table("../erm/midnorth_traumaPC_resid.txt", header=T)
midsouth <- read.table("../erm/midsouth_traumaPC_resid.txt", header=T)
southwest <- read.table("../erm/southwest_traumaPC_resid.txt", header=T)
southeast <- read.table("../erm/southeast_traumaPC_resid.txt", header=T)

pcs <- Reduce(function(x,y) rbind(x=x, y=y), list(north, midnorth, midsouth, southwest, southeast))
colnames(pcs)[1] <- "f.eid"

df <- Reduce(function(x,y) merge(x=x, y=y, by="f.eid", all.x=T, all.y=T), list(broad, cidi, neuro, pcs)) # n = 500988
df <- merge(cov, df, by="f.eid", all.x=T) # n = 457440

#################################
# DV ~ trauma PC associations   #
#################################

dv <- df

#cidi and broad depression

final_result <- c()

for(pheno in c("broad", "cidi")){
  for(col in c(8:23)){
    
    #using columns 8:23 (PC1:16)
    reg <- summary(glm(dv[,pheno] ~ age_0initial + sex + dv[,col], data = dv, family = "binomial"))
    reg2 <- summary(lm(dv[,pheno] ~ age_0initial + sex + dv[,col], data = dv, family = "binomial")) #using lm() to obtain R2
    
    result <- cbind(reg$coefficients, reg2$adj.r.squared, reg$df[2], col)
    colnames(result)[5] <- "AdjR2"
    final_result <- rbind(final_result, result)
  }
}

broad_results <- final_result[1:64,]
cidi_results <- final_result[65:128,]

write.csv(cidi_results, "cidi_traumaPCresid_associations.csv")
write.csv(broad_results, "broad_traumaPCresid_associations.csv")

#neuroticism

pheno <- "neuro"
final_result <- c()

for(col in c(8:23)){
  
  reg <- summary(lm(dv[,pheno] ~ age_0initial + sex + dv[,col], data=dv)) #running lm() to obtain R2
  result <- cbind(reg$coefficients, reg$adj.r.squared, reg$df[2], col)
  colnames(result)[5] <- "AdjR2"
  final_result <- rbind(final_result, result)
  
  write.csv(final_result, "neuro_traumaPCresid_associations.csv")

}

```


The PC_resid files are converted into bod files

```
#I am currently using a Linux machine, so will make use of the Linux executable of osca

wget https://cnsgenomics.com/software/osca/download/osca_Linux.zip
unzip osca_Linux.zip.

#I also need to make sure my software is executable
chmod u+x osca_Linux

./osca_Linux --efile north_traumaPC_resid.txt --make-bod --out traumaPCresid_north

./osca_Linux --efile midnorth_traumaPC_resid.txt --make-bod --out traumaPCresid_midnorth

./osca_Linux --efile midsouth_traumaPC_resid.txt --make-bod --out traumaPCresid_midsouth

./osca_Linux --efile southwest_traumaPC_resid.txt --make-bod --out traumaPCresid_southwest

./osca_Linux --efile southeast_traumaPC_resid.txt --make-bod --out traumaPCresid_southeast

```
Finally, I the cluster  ERMs are computed using the available bod files

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, June 2021
# Eddie UKB ERM Script

#$ -N trPC_resid_erm
#$ -cwd
#$ -pe sharedmem 5 # number of cores
#$ -l h_vmem=8G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line


# CREATING ORM FILES 

../osca_Linux --befile ../traumaPCresid_north --make-orm --out traumaPCresid_north --thread-num 5

../osca_Linux --befile ../traumaPCresid_midnorth --make-orm --out traumaPCresid_midnorth --thread-num 5

../osca_Linux --befile ../traumaPCresid_midsouth --make-orm --out traumaPCresid_midsouth --thread-num 5

../osca_Linux --befile ../traumaPCresid_southwest --make-orm --out traumaPCresid_southwest --thread-num 5

../osca_Linux --befile ../traumaPCresid_southeast --make-orm --out traumaPCresid_southeast --thread-num 5

```
### ERM Trauma (PC1:3)   

We also want to explore only PC1 (as its the PC that accounts for the most variance in our DVs). I also explore the next two trauma principal components separately as well (just for funsies).    

First I need to create a trauma PC1 (or PC2/PC3) text file for each cluster

```{r, eval=FALSE}
rm(list=ls())

#start by saving only PC1
pcs <- read.csv("../phenotypes/trauma_pcs.csv")
#HERE I CAN CHOOSE THE COLUMN OF PC2/PC3 
pcs <- pcs[,c(2:3)] #keeping only ID and PC1
colnames(pcs)[1] <- "FID"

#create profile.txt files for the single PC for each cluster
for(cluster in c("north", "midnorth", "midsouth", "southwest", "southeast")){
  ids <- read.table(paste0("../grm/gxe_keepIDs_", cluster, ".txt"), header=F)
  colnames(ids) <- c("FID", "IID")
  
cluster_pcs <- merge(ids, pcs, by="FID", all.x=TRUE)
  write.table(cluster_pcs, paste0("traumaPC1_", cluster, "_profile.txt"), row.names=F, quote=F)
}

```

Then convert to bod files

```
#I am currently using a Linux machine, so will make use of the Linux executable of osca

wget https://cnsgenomics.com/software/osca/download/osca_Linux.zip
unzip osca_Linux.zip.

#I also need to make sure my software is executable
chmod u+x osca_Linux

./osca_Linux --efile traumaPC1_north_profile.txt --make-bod --out traumaPC1_north

./osca_Linux --efile traumaPC1_midnorth_profile.txt --make-bod --out traumaPC1_midnorth

./osca_Linux --efile traumaPC1_midsouth_profile.txt --make-bod --out traumaPC1_midsouth

./osca_Linux --efile traumaPC1_southwest_profile.txt --make-bod --out traumaPC1_southwest

./osca_Linux --efile traumaPC1_southeast_profile.txt --make-bod --out traumaPC1_southeast

```
Finally, I will use OSCA to create the traumaPC1 ERM

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, June 2021
# Eddie UKB ERM Script

#$ -N trauma_PC1_erm
#$ -cwd
#$ -pe sharedmem 5 # number of cores
#$ -l h_vmem=8G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line


# CREATING ORM FILES 

../osca_Linux --befile ../traumaPC1_north --make-orm --out traumaPC1_north --thread-num 5

../osca_Linux --befile ../traumaPC1_midnorth --make-orm --out traumaPC1_midnorth --thread-num 5

../osca_Linux --befile ../traumaPC1_midsouth --make-orm --out traumaPC1_midsouth --thread-num 5

../osca_Linux --befile ../traumaPC1_southwest --make-orm --out traumaPC1_southwest --thread-num 5

../osca_Linux --befile ../traumaPC1_southeast --make-orm --out traumaPC1_southeast --thread-num 5

```

### ERM GCTA Compatability  

In order for GCTA to read the binary erm file, we need to re-name the files from orm. to grm. as if they are genomic relationship matrices   
```
find . -depth -name "*.orm.bin" -exec sh -c 'f="{}"; mv -- "$f" "${f%.orm.bin}.grm.bin"' \;

find . -depth -name "*.orm.id" -exec sh -c 'f="{}"; mv -- "$f" "${f%.orm.id}.grm.id"' \;

find . -depth -name "*.orm.N.bin" -exec sh -c 'f="{}"; mv -- "$f" "${f%.orm.N.bin}.grm.N.bin"' \;

```
# MIXED LINEAR MODELS:  

The REML approach is a particular form of maximum likelihood estimation that does not base estimates on a maximum likelihood fit of all the information, but instead uses a likelihood function calculated from a transformed set of data, so that nuisance parameters have no effect (Dodge, 2006). In the case of variance component estimation, the original data set is replaced by a set of contrasts calculated from the data, and the likelihood function is calculated from the probability distribution of these contrasts, according to the model for the complete data set.  

In particular, REML is used as a method for fitting linear mixed models. In contrast to the earlier maximum likelihood estimation, REML can produce unbiased estimates of variance and covariance parameters (Baker). Outputs give estimates of variance components!  

In this project I conduct MLM (method: REML) using GCTA (Yang et al., 2011) software. Here, we fit the relationship matrices as random effects - and the output computes the DV proportion of variance accounted for by the random effects.  

## Mixed Linear Model Prerequisites {.tabset}  

### MLM Covariates  

It is important to include covariates such as AGE, SEX and the top Principle Components of the (full sample) GRM in subsequent analyses. This is also important as it can give us insight to any demographic differences between the clusters - which may impact results!.

```{r, eval=FALSE} 

rm(list=ls())

cov <- read.table("../../../phenotypes/covariates", header=T)
cov <- cov[,c(1:7)] #using all covariates barring PCs

#FULL SAMPLE COVARIATES

for(cluster in c("north", "midnorth", "midsouth", "southwest", "southeast")){
  
  ids <- read.table(paste0("../analysis_sample_", cluster, ".grm.id"), header=F)
  colnames(ids) <- c("FID", "IID")
  
  pcs <- read.table(paste0(cluster, "_pcs.eigenvec"), header=F)
  colnames(pcs)[1:2] <- c("FID", "IID")
  
  covariates <- merge(ids, cov, by=c("FID", "IID"))
  covariates <- merge(covariates, pcs, by=c("FID", "IID"))
  
  discrete <- covariates[,c(1:3,6)] #choosing ids, sex, and array
  
  quant <- covariates[,c(1:2,5,8:22)] #choosing ids, age, and pcs
  
  write.table(discrete, paste0(cluster, "_cov"), col.names=F, row.names=F, quote=F)
  write.table(quant, paste0(cluster, "_q_cov"), col.names=F, row.names=F, quote=F)
  
}

#I WILL ALSO EXPLORE THESE ANALYSES IN SEX-SPECIFIC SAMPLES 
#So I need to remove sex from the covariates file

for(cluster in c("north", "midnorth", "midsouth", "southwest", "southeast")){
  
cov <- read.table(paste0(cluster, "_cov"), header=F)

cov <- cov[,-3] #removing sex column

write.table(cov, paste0(cluster, "_cov2"), row.names=F, quote=F, col.names=F)

}

```
### MLM Prevalence Rates

When we are dealing with non-continuous traits we need to specify a population prevalence rate (or incidence rate), so there are a few things we need to consider for our project - the 1st being that we are looking at 2 different definitions of depression; CIDI and BROAD. The prevalence rates of these 2 different definitions are different, especially as broad dep is more of a measure of psychological distress which also captures anxiety. However, there isnt a clear indication of prevalence rates (and differences) between the different definitions.  

More importantly, we know there are prevalence rate differences between males and females - this is also important as I want to explore the effects in sex-specific samples as well. 

UKB is a sample population, so I will use the prevalence rates of CIDI and BROAD depression available in the whole UKB sample as my prevalence rates throughout the analyses. (There are some limitations to this, for example, we know that the UKB is actually a very healthy sample, so prevalence rates within this population might not actually be a true representation of the prevalence rates)  

```{r, eval=FALSE}

################################
##             BROAD          ##
################################

#lets obtain population prevalence 

broad <- read.table("broad_df", header=T)
# case = 171979 // control = 314186 //prev == 0.3537
colnames(broad)[1] <- c("FID")

cov <- read.table("covariates", header=T)
cov <- cov[,1:2]

df <- merge(broad, cov, by="FID") # n = 442911
df_f <- subset(df, df$sex=="Female") # n = 239238
# case = 103238 // control = 136000 // prev == 0.4315


df_m <- subset(df, df$sex=="Male") # n = 203673
# case = 55733 // control = 147940 // prev == 0.2736

################################
##            CIDI            ##
################################

cidi <- read.table("cidi_df", header=T)
cidi <- cidi[,c(1,15)] # keeping f.eid and case status
# case = 36482 // control = 92918 // prev == 0.2819
colnames(cidi)[1] <- "FID"

cov <- read.table("covariates", header=T)
cov <- cov[,1:2]

df <- merge(cidi, cov, by="FID") # n = 121877
df_f <- subset(df, df$sex=="Female") # n = 67059
# case = 23846 // control = 43213 // prev == 0.3556


df_m <- subset(df, df$sex=="Male") # n = 54818
# case = 10646 // control = 44172 // prev == 0.1942


```








## The 4 Main MLMs {.tabset}  

$$ 1. DV \sim X\beta + G + \varepsilon $$  
$$ 2. DV \sim X\beta + E + \varepsilon $$  
$$ 3. DV \sim X\beta + G + E + \varepsilon $$  
$$ 4. DV \sim X\beta + G + E + G.E + \varepsilon $$

Where y is a n×1 vector of observed depression/neuroticism phenotypes; β is a vector of fixed effects (which include age, sex, genotyping array and the first 15 principal components of the full sample GRM) and X is its design matrix; G is a n×1 vector of SNP effects (representing additive genetic effects) with G ~ (0,GRMσ_GRM^2 ); E is a n×1 vector representing common environmental effects of childhood, adult, catastrophic or all trauma with E ~ (0,ERMσ_ERM^2 ); GxE is a n×1 vector representing interactions between genetic and trauma effects with GxE ~ (0,GRMxERMσ_GRMxERM^2 ); and ε is a n×1 vector of residual effects.  

### Model 1

Here I will run a mixed linear model using REML; fitting the GRMs (whole sample) for each cluster as a random effect and covariates; AGE, SEX, GENOTYPING ARRAY and the top 10 PCs of the GRM as fixed effects.  

I will also run this analysis using GRMs limited to only unrelated participants - for this I just need to change the path of the GRM to that of the unrelated ps GRMs '../unrelated_grms/north_unrelated'

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, MAY 2021
# Eddie UKB VCA Script

#$ -N cidi_h2
#$ -cwd
#$ -pe sharedmem 8 # number of cores
#$ -l h_vmem=16G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

gcta64 --grm ../full_sample_grms/analysis_sample_north --reml --pheno cidi.phen --out h2_cidi_n --thread-num 8 --prevalence 0.28 --qcovar ../full_sample_grms/pca_full/north_q_cov --covar ../full_sample_grms/pca_full/north_cov --reml-est-fix

gcta64 --grm ../full_sample_grms/analysis_sample_midnorth --reml --pheno cidi.phen --out h2_cidi_mn --thread-num 8 --prevalence 0.28 --qcovar ../full_sample_grms/pca_full/midnorth_q_cov --covar ../full_sample_grms/pca_full/midnorth_cov --reml-est-fix

gcta64 --grm ../full_sample_grms/analysis_sample_midsouth  --reml --pheno cidi.phen --out h2_cidi_ms --thread-num 8 --prevalence 0.28 --qcovar ../full_sample_grms/pca_full/midsouth_q_cov --covar ../full_sample_grms/pca_full/midsouth_cov --reml-est-fix

gcta64 --grm ../full_sample_grms/analysis_sample_southwest --reml --pheno cidi.phen --out h2_cidi_sw --thread-num 8 --prevalence 0.28 --qcovar ../full_sample_grms/pca_full/southwest_q_cov --covar ../full_sample_grms/pca_full/southwest_cov --reml-est-fix

gcta64 --grm ../full_sample_grms/analysis_sample_southeast  --reml --pheno cidi.phen --out h2_cidi_se --thread-num 8 --prevalence 0.28 --qcovar ../full_sample_grms/pca_full/southeast_q_cov --covar ../full_sample_grms/pca_full/southeast_cov --reml-est-fix

```







### Model 1.2  

Good practice when exploring variance components and making use of GRMs is to also include a kinship matrix within the analysis. This ensures that you are keeping all (including relatives) participants within the analyses and still controlling for potential biases that may arise with the use of relatives!  

Whilst the dataset that I have only has a few relatives, I will run the model with G + K for good practice!

I need to create a text file listing the path to the GRM and kinship matrix files **e.g. north_mgrm.txt**  

```
../kinship_matrix/north_bK

../full_sample_grms/analysis_sample_north

```
Then I will run the reml analysis  

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, MAY 2021
# Eddie UKB VCA Script

#$ -N cidi_h2_bK
#$ -cwd
#$ -pe sharedmem 10 # number of cores
#$ -l h_vmem=16G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

gcta64 --mgrm north_mgrm.txt --reml --pheno cidi.phen --out h2_cidi_bK_n --thread-num 10 --prevalence 0.28 --qcovar ../full_sample_grms/pca_full/north_q_cov --covar ../full_sample_grms/pca_full/north_cov --reml-lrt 1 2 --reml-est-fix                
gcta64 --mgrm midnorth_mgrm.txt --reml --pheno cidi.phen --out h2_cidi_bK_mn --thread-num 10 --prevalence 0.28 --qcovar ../full_sample_grms/pca_full/midnorth_q_cov --covar ../full_sample_grms/pca_full/midnorth_cov --reml-lrt 1 2 --reml-est-fix

gcta64 --mgrm midsouth_mgrm.txt  --reml --pheno cidi.phen --out h2_cidi_bK_ms --thread-num 10 --prevalence 0.28 --qcovar ../full_sample_grms/pca_full/midsouth_q_cov --covar ../full_sample_grms/pca_full/midsouth_cov --reml-lrt 1 2 --reml-est-fix

gcta64 --mgrm southwest_mgrm.txt  --reml --pheno cidi.phen --out h2_cidi_bK_sw --thread-num 10 --prevalence 0.28 --qcovar ../full_sample_grms/pca_full/southwest_q_cov --covar ../full_sample_grms/pca_full/southwest_cov --reml-lrt 1 2 --reml-est-fix

gcta64 --mgrm southeast_mgrm.txt   --reml --pheno cidi.phen --out h2_cidi_bK_se --thread-num 10 --prevalence 0.28 --qcovar ../full_sample_grms/pca_full/southeast_q_cov --covar ../full_sample_grms/pca_full/southeast_cov --reml-lrt 1 2 --reml-est-fix

```

### Model 2  

Remember that I want to explore a range of ERMs, e.g. ERMs computed using all 16 trauma PCs, 16 trauma PC residuals, 1:3 trauma PCs - all downstream models will need to be altered depending on the ERM utilised. In this section I will use the ERM computed using all 16 trauma PCs.  

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, MAY 2021
# Eddie UKB VCA Script

#$ -N cidi_erm_reml
#$ -cwd
#$ -pe sharedmem 10 # number of cores
#$ -l h_vmem=16G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

gcta64 --grm ../erm_full/trauma_north --reml --prevalence 0.28 --pheno cidi.phen --out h2_cidi_erm_n --thread-num 10  --qcovar ../../../grm/full_sample_grms/pca_full/north_q_cov --covar ../../../grm/full_sample_grms/pca_full/north_cov --reml-est-fix --reml-est-fix --reml-priors 0 1  

gcta64 --grm ../erm_full/trauma_midnorth --reml --prevalence 0.28 --pheno cidi.phen --out h2_cidi_erm_mn --thread-num 10 --qcovar ../../../grm/full_sample_grms/pca_full/midnorth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midnorth_cov --reml-est-fix --reml-est-fix --reml-priors 0 1

gcta64 --grm ../erm_full//trauma_midsouth --reml --prevalence 0.28 --pheno cidi.phen --out h2_cidi_erm_ms --thread-num 10 --qcovar ../../../grm/full_sample_grms/pca_full/midsouth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midsouth_cov --reml-est-fix --reml-est-fix --reml-priors 0 1

gcta64 --grm ../erm_full/trauma_southwest --reml --prevalence 0.28 --pheno cidi.phen --out h2_cidi_erm_sw --thread-num 10 --qcovar ../../../grm/full_sample_grms/pca_full/southwest_q_cov --covar ../../../grm/full_sample_grms/pca_full/southwest_cov --reml-est-fix --reml-est-fix --reml-priors 0 1

gcta64 --grm ../erm_full/trauma_southeast --reml --prevalence 0.28 --pheno cidi.phen --out h2_cidi_erm_se --thread-num 10 --qcovar ../../../grm/full_sample_grms/pca_full/southeast_q_cov --covar ../../../grm/full_sample_grms/pca_full/southeast_cov --reml-est-fix --reml-est-fix --reml-priors 0 1

```








### Model 3  

Remember that I want to explore a range of ERMs, e.g. ERMs computed using all 16 trauma PCs, 16 trauma PC residuals, 1:3 trauma PCs - all downstream models will need to be altered depending on the ERM utilised. In this section I will use the ERM computed using all 16 trauma PCs.  

First I create a txt file detailing the paths of the GRM and ERM **e.g. mgrm_G+E_north.txt**  
```
../../erm_full_alg1/trauma_north
../../../grm/full_sample_grms/analysis_sample_north

```
Then I run REML analysis

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, MAY 2021
# Eddie UKB VCA Script

#$ -N cidi_g+e_h2_bK
#$ -cwd
#$ -pe sharedmem 10 # number of cores
#$ -l h_vmem=16G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

gcta64 --mgrm mgrm_G+E_north.txt --reml --pheno ../cidi.phen --out h2_cidi_G+E_n --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/north_q_cov --covar ../../../grm/full_sample_grms/pca_full/north_cov --reml-lrt 1 --reml-est-fix  

gcta64 --mgrm mgrm_G+E_midnorth.txt --reml --pheno ../cidi.phen --out h2_cidi_G+E_mn --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/midnorth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midnorth_cov --reml-lrt 1 --reml-est-fix

gcta64 --mgrm mgrm_G+E_midsouth.txt  --reml --pheno ../cidi.phen --out h2_cidi_G+E_ms --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/midsouth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midsouth_cov --reml-lrt 1 --reml-est-fix

gcta64 --mgrm mgrm_G+E_southwest.txt  --reml --pheno ../cidi.phen --out h2_cidi_G+E_sw --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/southwest_q_cov --covar ../../../grm/full_sample_grms/pca_full/southwest_cov --reml-lrt 1 --reml-est-fix

gcta64 --mgrm mgrm_G+E_southeast.txt   --reml --pheno ../cidi.phen --out h2_cidi_G+E_se --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/southeast_q_cov --covar ../../../grm/full_sample_grms/pca_full/southeast_cov --reml-lrt 1 --reml-est-fix

```
### Model 4  

Remember that I want to explore a range of ERMs, e.g. ERMs computed using all 16 trauma PCs, 16 trauma PC residuals, 1:3 trauma PCs - all downstream models will need to be altered depending on the ERM utilised. In this section I will use the ERM computed using all 16 trauma PCs.  

To explore the interaction effect a relationship matrix for interactions needs to be created  
We will use the hadamard product, which is a cell by cell multiplication of 2 matrices with the same dimensions  

1. I start by creating an executable file for interaction matrices. This part only needs to be done ONCE!   

The first line loads intel's fortran compiler

```
module load intel

```
I create a script that generates an executable file HadarmardProd.90, using 'vi'

```
vi HadamardProd.f90

```
With the following info pasted inside the file  
Code provided by Carmen Amador  

```

      PROGRAM Hadamard_Products
	  ! Computes the Hadamard Prod of two matrices G1 and G2
	  ! IDs of the individuals need to be NUMERIC
	  ! C.Amador Edinburgh 24/02/2019
	  ! To compile:
	  ! >> module load intel
	  ! >> ifort -o HadamardP HadamardProd.f90
	  ! run with RunHadamardP.sh
	  
	  IMPLICIT NONE
	  INTEGER:: i, j, NIND, N_ENTRIES
	  INTEGER:: IDs_G2, IDs_G1
	  REAL:: G1, G2, G1xG2, G1xG2_N
	  CHARACTER*50:: arg1, arg2, arg3, arg4
	  CHARACTER*100:: G1NAM, G2NAM, G3NAM
	  CHARACTER*100:: G1_i_file, G2_i_file, G1id_i_file, G2id_i_file
	  CHARACTER*100:: G1xG2_o_file, G1xG2_N_o_file, G1xG2id_o_file
	  INTEGER, DIMENSION(8):: valuesB, valuesE ! Time computing variables     
	  ALLOCATABLE:: IDs_G2(:,:), IDs_G1(:,:), G1xG2_N(:)
	  
	  ! Reads the arguments needed   
	  CALL get_command_argument(1, arg1) ! reads the first value passed in the command line
	  CALL get_command_argument(2, arg2) ! reads the second value passed in the command line	  
	  CALL get_command_argument(3, arg3) ! reads the third value passed in the command line   
	  CALL get_command_argument(4, arg4) ! reads the fourth value passed in the command line      
	  
	  CALL DATE_AND_TIME(VALUES=valuesB)		  

	  ! Prints the initial hello stuff	  
	  PRINT*, ""
	  PRINT*, "Hadamard Products C.Amador Oct/2019"
	  PRINT*, "Computes the Hadamard Prod of two matrices G1 and G2"   
	  PRINT'(a20,i2,a1,i2,a1,i2,a2,i2,a1,i2,a1,i4)', "Analysis started:", &
	  valuesB(5),":",valuesB(6),":",valuesB(7)," ",valuesB(3),"/",valuesB(2),"/",valuesB(1)	  
	  PRINT*,""
	  
	  ! Checks for errors in the arguments passed	  
	  IF ((LEN_TRIM(arg1)==0).OR.(LEN_TRIM(arg2)==0).OR.(LEN_TRIM(arg3)==0).OR.(LEN_TRIM(arg4)==0)) THEN
	    PRINT *, "ERROR!"
	    PRINT *, "Are you sure you passed on the 4 required arguments?"
	    PRINT *, "The 4 required arguments are: "
	    PRINT *, "N. individuals, Name of the first Matrix, Name of the second Matrix, Name of the output"
	    STOP
	  ENDIF
	  
	  READ(arg1,*) NIND ! the first number is #individuals
	  N_ENTRIES = (NIND*(NIND+1))/2
	  READ(arg2,*) G1NAM ! the second position is the name of the G1
	  READ(arg3,*) G2NAM ! the third position is the name of the G2
	  READ(arg4,*) G3NAM ! the third position is the name of the output
	  
	  G1_i_file = trim(G1NAM) // '.grm.bin'
	  G1id_i_file = trim(G1NAM) // '.grm.id'
	  G2_i_file = trim(G2NAM) // '.grm.bin'
	  G2id_i_file = trim(G2NAM) // '.grm.id'
	  G1xG2_o_file = trim(G3NAM) // '.grm.bin'
	  G1xG2_N_o_file = trim(G3NAM) // '.grm.N.bin'
	  G1xG2id_o_file = trim(G3NAM) // '.grm.id'
	  
	  PRINT *, '#1 Reading G1 ids: ', trim(G1id_i_file)	  
	  ALLOCATE(IDs_G1(NIND,2))  
	  OPEN(4, file=trim(G1id_i_file))   
	  ! Reads the G1 ids
	  DO i= 1, NIND
	    READ(4,*) IDs_G1(i,1:2)
	  ENDDO	  
	  CLOSE(4)
	  
	  PRINT *, '#2 Reading G2 ids: ',  trim(G2id_i_file)  
	  ALLOCATE(IDs_G2(NIND,2))
	  OPEN(4, file=trim(G2id_i_file))   
	  ! Reads the G2 ids
	  DO i= 1, NIND
	    READ(4,*) IDs_G2(i,1:2)
	  ENDDO	  
	  CLOSE(4)	  
	  
	  ! Compares IDs in E and G to doublecheck order
	  DO i= 1, NIND
	    IF (IDs_G1(i,1).NE.IDs_G2(i,1)) THEN
	     PRINT *, "ERROR!"
	     PRINT *, "IDs G2 and G1 don't match! Please check the order"
	     STOP 
	   ENDIF
	  ENDDO		  
	  PRINT *, '#3 Id order is correct!'	
	  
	  PRINT *, '#4 Writing G1xG2.ids : ', trim(G1xG2id_o_file)	  
      OPEN(4, file=trim(G1xG2id_o_file))   
      ! Reads the GRM ids
      DO i= 1, NIND
       WRITE(4,*) IDs_G1(i,1:2)
      ENDDO	  
      CLOSE(4)	

	  
	  PRINT *, '#5 Reading, Multiplying and Writing: ', trim(G1xG2_o_file)	
	  OPEN(UNIT = 5, file=trim(G1_i_file), form='unformatted', access='stream')
	  OPEN(UNIT = 6, file=trim(G2_i_file), form='unformatted', access='stream')
	  OPEN(UNIT = 7, file=trim(G1xG2_o_file), form = 'unformatted', access='stream')
	  
	  G1=0
	  G2=0
	  G1xG2=0
	  DO i= 1, NIND
        DO j= 1, i
		    READ(5) G1
		    READ(6) G2
      	 	G1xG2 = G1*G2
			WRITE(7) G1xG2
		    G1=0
			G2=0
			G1xG2=0	 
        ENDDO
      ENDDO	  
	  
	  CLOSE(5)	
	  CLOSE(6)	
	  CLOSE(7)  
	  
	  ! Writes the G1xG2.N.bin file 
      PRINT *, '#6 Writing G1xG2.grm.N.bin: ', trim(G1xG2_N_o_file)
	  ALLOCATE(G1xG2_N(N_ENTRIES))
	  G1xG2_N=100
	  OPEN(UNIT = 7, FORM = "unformatted", FILE = trim(G1xG2_N_o_file), access='stream')
      WRITE(7) G1xG2_N  
      CLOSE(7) 	


	  
	  ! Time and wrapping up
	  CALL DATE_AND_TIME(VALUES=valuesE)	  
	  PRINT*," "	  
	  PRINT'(a20,i2,a1,i2,a1,i2,a2,i2,a1,i2,a1,i4)', "ALL Done :) ", &
	  valuesE(5),":",valuesE(6),":",valuesE(7)," ",valuesE(3),"/",valuesE(2),"/",valuesE(1)		  
   	  PRINT*, ""
	  
    END PROGRAM Hadamard_Products
    
```
I run this script to create the executable file

```
ifort -o HadamardP HadamardProd.f90

```
2. I create a shell script (code provided by Carmen Amador) to specify which matrices to use for the final interaction matrix  

Where NIND is the sample size of grm.id  
G1 is the first matrix  
G2 is the second matrix  
Out is the name of the interaction matrix  

Making sure all files are in the same directory will make this process run smoothly  
Remember to run the following script for all clusters (just providing north as an example)

```
NIND=24287
G1=$'analysis_sample_north'
G2=$'trauma_north'
Out=$'GxTRAUMA_north'

./HadamardP $NIND $G1 $G2 $Out > $Out.log

## WARNING
## For Nind>>> the grm.N.bin file might be problematic, copy from G or E matrix:
## cp $G1.grm.N.bin GxE_$Out.grm.N.bin

```
To create the interaction matrices

```
./RunHadamardP_north.sh

```
3. We need to copy the GRM.grm.N.bin files and save as GxTrauma.grm.N.bin files - following warning provided by Carmen

```
cp analysis_sample_north.grm.N.bin GxTRAUMA_north.grm.N.bin

cp analysis_sample_midnorth.grm.N.bin GxTRAUMA_midnorth.grm.N.bin

cp analysis_sample_midsouth.grm.N.bin GxTRAUMA_midsouth.grm.N.bin

cp analysis_sample_southwest.grm.N.bin GxTRAUMA_southwest.grm.N.bin

cp analysis_sample_southeast.grm.N.bin GxTRAUMA_southeast.grm.N.bin

```

4. Create a text file listing the pathway to the different relationship matrices  

```
vi mgrm_GxE_north.txt

```
By typing 'i' (for insert) I add the following paths

```
../alg1_files/analysis_sample_north

../alg1_files/trauma_north

../alg1_files/GxTRAUMA_north

```
To save and quite, press the 'esc' button and type 'wq' (write quit). 

4. Run the reml analysis  
Remember to run these analyses for the other DVs, just using CIDI depression as an example here

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, MAY 2021
# Eddie UKB VCA Script

#$ -N cidi_gxe_h2
#$ -cwd
#$ -pe sharedmem 10 # number of cores
#$ -l h_vmem=16G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

gcta64 --mgrm mgrm_GxE_north.txt --reml --pheno cidi.phen --out h2_cidi_GxE_n --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/north_q_cov --covar ../../../grm/full_sample_grms/pca_full/north_cov --reml-lrt 3 --reml-est-fix  

gcta64 --mgrm mgrm_GxE_midnorth.txt --reml --pheno cidi.phen --out h2_cidi_GxE_mn --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/midnorth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midnorth_cov --reml-lrt 3 --reml-est-fix

gcta64 --mgrm mgrm_GxE_midsouth.txt  --reml --pheno cidi.phen --out h2_cidi_GxE_ms --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/midsouth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midsouth_cov --reml-lrt 3 --reml-est-fix

gcta64 --mgrm mgrm_GxE_southwest.txt  --reml --pheno cidi.phen --out h2_cidi_GxE_sw --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/southwest_q_cov --covar ../../../grm/full_sample_grms/pca_full/southwest_cov --reml-lrt 3 --reml-est-fix

gcta64 --mgrm mgrm_GxE_southeast.txt   --reml --pheno cidi.phen --out h2_cidi_GxE_se --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/southeast_q_cov --covar ../../../grm/full_sample_grms/pca_full/southeast_cov --reml-lrt 3 --reml-est-fix

```
### Sex Specific Analyses  

Here I want to explore the reml MLMs using a GRM, ERM, GRM+ERM and GRMxERM within FEMALE only and MALE only samples - as effects that we are observing may be sex specific. We know that women are more likely to go onto develop depression and thus, this is a good motivator to explore the sexes separately.  

Remember that we are using algorithm 1 to compute the ERMs. Remember that the following scripts are also repeated for cidi depression males as well as broad depression and neuroticism (male and female) - these scripts have 1 alteration, cidi depression male prevalence is 0.19 and broad depression prevalence rate is specified as 0.27 for males, 0.43 for females. As neuroticism is not a binary trait, no conversion to the liability scale is necessary.  

Also, here we will be using different covariate files (cov2) where I have removed SEX as a covariate (see above section 'Covariates for REML analyses).  

For this, I first need to create sex-specific DV .phen files  

```{r, eval=FALSE}
#covariates
cov <- read.table("../phenotypes/covariates", header=T)
cov <- cov[,1:2] #extracting ID + SEX data n = 457440

for(DV in c("broad", "cidi", "neuro")){

dv <- read.table(paste0(DV, ".phen"), header=F)
colnames(dv)[1] <- "FID"
dv <- merge(dv, cov, by="FID")

female <- subset(dv, dv$sex=="Female")
female <- female[,-4] #we remove the sex col, no need for this
  male <- subset(dv, dv$sex=="Male")
  male <- male[,-4]
  

write.table(female, paste0(DV,"_female.phen"), row.names=F, quote=F, col.names=F)

write.table(male, paste0(DV, "_male.phen"), row.names=F, quote=F, col.names=F)
}

```

Run REML analysis (Model 1)  

**Remember the following scripts are repeated with 'female' replaced with 'male'.**  

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, MAY 2021
# Eddie UKB VCA Script

#$ -N cidi_F_h2
#$ -cwd
#$ -pe sharedmem 8 # number of cores
#$ -l h_vmem=16G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

gcta64 --grm ../full_sample_grms/analysis_sample_north --reml --pheno cidi_female.phen --out h2_female_cidi_n --thread-num 8 --prevalence 0.35 --qcovar ../full_sample_grms/pca_full/north_q_cov --covar ../full_sample_grms/pca_full/north_cov2 --reml-est-fix

gcta64 --grm ../full_sample_grms/analysis_sample_midnorth --reml --pheno cidi_female.phen --out h2_female_cidi_mn --thread-num 8 --prevalence 0.35 --qcovar ../full_sample_grms/pca_full/midnorth_q_cov --covar ../full_sample_grms/pca_full/midnorth_cov2 --reml-est-fix

gcta64 --grm ../full_sample_grms/analysis_sample_midsouth  --reml --pheno cidi_female.phen --out h2_female_cidi_ms --thread-num 8 --prevalence 0.35 --qcovar ../full_sample_grms/pca_full/midsouth_q_cov --covar ../full_sample_grms/pca_full/midsouth_cov2 --reml-est-fix

gcta64 --grm ../full_sample_grms/analysis_sample_southwest --reml --pheno cidi_female.phen --out h2_female_cidi_sw --thread-num 8 --prevalence 0.35 --qcovar ../full_sample_grms/pca_full/southwest_q_cov --covar ../full_sample_grms/pca_full/southwest_cov2 --reml-est-fix

gcta64 --grm ../full_sample_grms/analysis_sample_southeast  --reml --pheno cidi_female.phen --out h2_female_cidi_se --thread-num 8 --prevalence 0.35 --qcovar ../full_sample_grms/pca_full/southeast_q_cov --covar ../full_sample_grms/pca_full/southeast_cov2 --reml-est-fix

```
Run REML Analysis (Model 2) 

**Remember the following scripts are repeated with 'female' replaced with 'male'.**  

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, MAY 2021
# Eddie UKB VCA Script

#$ -N cidi_F_erm_reml
#$ -cwd
#$ -pe sharedmem 10 # number of cores
#$ -l h_vmem=8G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

gcta64 --grm ../../erm_full_alg1/trauma_north --reml --prevalence 0.35 --pheno cidi_female.phen --out h2_female_cidi_erm_n --thread-num 10  --qcovar ../../../grm/full_sample_grms/pca_full/north_q_cov --covar ../../../grm/full_sample_grms/pca_full/north_cov2 --reml-est-fix  

gcta64 --grm ../../erm_full_alg1/trauma_midnorth --reml --prevalence 0.35 --pheno cidi_female.phen --out h2_female_cidi_erm_mn --thread-num 10 --qcovar ../../../grm/full_sample_grms/pca_full/midnorth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midnorth_cov2 --reml-est-fix

gcta64 --grm ../../erm_full_alg1/trauma_midsouth --reml --prevalence 0.35 --pheno cidi_female.phen --out h2_female_cidi_erm_ms --thread-num 10 --qcovar ../../../grm/full_sample_grms/pca_full/midsouth_q_cov --covar ../../grm/full_sample_grms/pca_full/midsouth_cov2 --reml-est-fix

gcta64 --grm ../../erm_full_alg1/trauma_southwest --reml --prevalence 0.35 --pheno cidi_female.phen --out h2_female_cidi_erm_sw --thread-num 10 --qcovar ../../../grm/full_sample_grms/pca_full/southwest_q_cov --covar ../../../grm/full_sample_grms/pca_full/southwest_cov2 --reml-est-fix

gcta64 --grm ../../erm_full_alg1/trauma_southeast --reml --prevalence 0.35 --pheno cidi_female.phen --out h2_female_cidi_erm_se --thread-num 10 --qcovar ../../../grm/full_sample_grms/pca_full/southeast_q_cov --covar ../../../grm/full_sample_grms/pca_full/southeast_cov2 --reml-est-fix

```
Run REML Analysis (Model 3)

**Remember the following scripts are repeated with 'female' replaced with 'male'.**   

Will create a txt file detailing the paths of the GRM and ERM

```
vi mgrm_G+E_north.txt
```
By typing 'i' (for insert) I add the following paths

```
../../erm_full_alg1/trauma_north
../../../grm/full_sample_grms/analysis_sample_north

```
To save and quite, press the 'esc' button and type 'wq' (write quit).  

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, MAY 2021
# Eddie UKB VCA Script

#$ -N cidi_F_g+e_h2
#$ -cwd
#$ -pe sharedmem 10 # number of cores
#$ -l h_vmem=8G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

gcta64 --mgrm mgrm_G+E_north.txt --reml --pheno ../cidi_female.phen --out h2_female_cidi_G+E_n --thread-num 10 --prevalence 0.35 --qcovar ../../../grm/full_sample_grms/pca_full/north_q_cov --covar ../../../grm/full_sample_grms/pca_full/north_cov2 --reml-lrt 1 --reml-est-fix  

gcta64 --mgrm mgrm_G+E_midnorth.txt --reml --pheno ../cidi_female.phen --out h2_female_cidi_G+E_mn --thread-num 10 --prevalence 0.35 --qcovar ../../../grm/full_sample_grms/pca_full/midnorth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midnorth_cov2 --reml-lrt 1 --reml-est-fix

gcta64 --mgrm mgrm_G+E_midsouth.txt  --reml --pheno ../cidi_female.phen --out h2_female_cidi_G+E_ms --thread-num 10 --prevalence 0.35 --qcovar ../../../grm/full_sample_grms/pca_full/midsouth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midsouth_cov2 --reml-lrt 1 --reml-est-fix

gcta64 --mgrm mgrm_G+E_southwest.txt  --reml --pheno ../cidi_female.phen --out h2_female_cidi_G+E_sw --thread-num 10 --prevalence 0.35 --qcovar ../../../grm/full_sample_grms/pca_full/southwest_q_cov --covar ../../../grm/full_sample_grms/pca_full/southwest_cov2 --reml-lrt 1 --reml-est-fix

gcta64 --mgrm mgrm_G+E_southeast.txt   --reml --pheno ../cidi_female.phen --out h2_female_cidi_G+E_se --thread-num 10 --prevalence 0.35 --qcovar ../../../grm/full_sample_grms/pca_full/southeast_q_cov --covar ../../../grm/full_sample_grms/pca_full/southeast_cov2 --reml-lrt 1 --reml-est-fix

```
Run REML Analysis (Model 4)  

First we create the files containing the path location of the relationship matrices  

```
vi mgrm_GxE_north.txt

```
By typing 'i' (for insert) I add the following paths

```
../alg1_files/analysis_sample_north

../alg1_files/trauma_north

../alg1_files/GxTRAUMA_north

```
To save and quite, press the 'esc' button and type 'wq' (write quit). 

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, MAY 2021
# Eddie UKB VCA Script

#$ -N cidi_F_gxe_h2
#$ -cwd
#$ -pe sharedmem 10 # number of cores
#$ -l h_vmem=8G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

gcta64 --mgrm mgrm_GxE_north.txt --reml --pheno cidi_female.phen --out h2_female_cidi_GxE_n --thread-num 10 --prevalence 0.35 --qcovar ../../../grm/full_sample_grms/pca_full/north_q_cov --covar ../../../grm/full_sample_grms/pca_full/north_cov2 --reml-lrt 3 --reml-est-fix  

gcta64 --mgrm mgrm_GxE_midnorth.txt --reml --pheno cidi_female.phen --out h2_female_cidi_GxE_mn --thread-num 10 --prevalence 0.35 --qcovar ../../../grm/full_sample_grms/pca_full/midnorth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midnorth_cov2 --reml-lrt 3 --reml-est-fix

gcta64 --mgrm mgrm_GxE_midsouth.txt  --reml --pheno cidi_female.phen --out h2_female_cidi_GxE_ms --thread-num 10 --prevalence 0.35 --qcovar ../../../grm/full_sample_grms/pca_full/midsouth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midsouth_cov2 --reml-lrt 3 --reml-est-fix

gcta64 --mgrm mgrm_GxE_southwest.txt  --reml --pheno cidi_female.phen --out h2_female_cidi_GxE_sw --thread-num 10 --prevalence 0.35 --qcovar ../../../grm/full_sample_grms/pca_full/southwest_q_cov --covar ../../../grm/full_sample_grms/pca_full/southwest_cov2 --reml-lrt 3 --reml-est-fix

gcta64 --mgrm mgrm_GxE_southeast.txt   --reml --pheno cidi_female.phen --out h2_female_cidi_GxE_se --thread-num 10 --prevalence 0.35 --qcovar ../../../grm/full_sample_grms/pca_full/southeast_q_cov --covar ../../../grm/full_sample_grms/pca_full/southeast_cov2 --reml-lrt 3 --reml-est-fix

```
### Trauma PCs Residualised  

Here I do not need to run Model 1, as the REML results using the GRMs will remain the same!  

Run reml analysis (Model 2)  

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, MAY 2021
# Eddie UKB VCA Script

#$ -N cidi_ermPCresid_reml
#$ -cwd
#$ -pe sharedmem 10 # number of cores
#$ -l h_vmem=16G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

gcta64 --grm ../../erm_PCresid/traumaPCresid_north --reml --pheno ../cidi.phen --out h2_cidi_ermPCresid_n --prevalence 0.28 --thread-num 10  --qcovar ../../../grm/full_sample_grms/pca_full/north_q_cov --covar ../../../grm/full_sample_grms/pca_full/north_cov --reml-est-fix  

gcta64 --grm ../../erm_PCresid/traumaPCresid_midnorth --reml --pheno ../cidi.phen --out h2_cidi_ermPCresid_mn --prevalence 0.28 --thread-num 10 --qcovar ../../../grm/full_sample_grms/pca_full/midnorth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midnorth_cov --reml-est-fix

gcta64 --grm ../../erm_PCresid/traumaPCresid_midsouth --reml --pheno ../cidi.phen --out h2_cidi_ermPCresid_ms --prevalence 0.28 --thread-num 10 --qcovar ../../../grm/full_sample_grms/pca_full/midsouth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midsouth_cov --reml-est-fix

gcta64 --grm ../../erm_PCresid/traumaPCresid_southwest --reml --pheno ../cidi.phen --out h2_cidi_ermPCresid_sw --prevalence 0.28 --thread-num 10 --qcovar ../../../grm/full_sample_grms/pca_full/southwest_q_cov --covar ../../../grm/full_sample_grms/pca_full/southwest_cov --reml-est-fix

gcta64 --grm ../../erm_PCresid/traumaPCresid_southeast --reml --pheno ../cidi.phen --out h2_cidi_ermPCresid_se --prevalence 0.28 --thread-num 10 --qcovar ../../../grm/full_sample_grms/pca_full/southeast_q_cov --covar ../../../grm/full_sample_grms/pca_full/southeast_cov --reml-est-fix

```
Run REML analysis (Model 3)

```
vi mgrm_G+E_north.txt
```
By typing 'i' (for insert) I add the following paths

```
../../erm_PCresid/traumaPCresid_north
../../../grm/full_sample_grms/analysis_sample_north

```
To save and quite, press the 'esc' button and type 'wq' (write quit). 

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, MAY 2021
# Eddie UKB VCA Script

#$ -N cidi_g+e_PCresid_h2_bK
#$ -cwd
#$ -pe sharedmem 10 # number of cores
#$ -l h_vmem=16G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

gcta64 --mgrm mgrm_G+E_north.txt --reml --pheno ../cidi.phen --out h2_cidi_G+E_PC1_n --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/north_q_cov --covar ../../../grm/full_sample_grms/pca_full/north_cov --reml-lrt 1 --reml-est-fix  

gcta64 --mgrm mgrm_G+E_midnorth.txt --reml --pheno ../cidi.phen --out h2_cidi_G+E_PC1_mn --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/midnorth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midnorth_cov --reml-lrt 1 --reml-est-fix

gcta64 --mgrm mgrm_G+E_midsouth.txt  --reml --pheno ../cidi.phen --out h2_cidi_G+E_PC1_ms --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/midsouth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midsouth_cov --reml-lrt 1 --reml-est-fix

gcta64 --mgrm mgrm_G+E_southwest.txt  --reml --pheno ../cidi.phen --out h2_cidi_G+E_PC1_sw --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/southwest_q_cov --covar ../../../grm/full_sample_grms/pca_full/southwest_cov --reml-lrt 1 --reml-est-fix

gcta64 --mgrm mgrm_G+E_southeast.txt   --reml --pheno ../cidi.phen --out h2_cidi_G+E_PC1_se --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/southeast_q_cov --covar ../../../grm/full_sample_grms/pca_full/southeast_cov --reml-lrt 1 --reml-est-fix

```
Run REML Analysis (Model 4)

I create a shell script (code provided by Carmen Amador) to specify which matrices to use for the final interaction matrix  

Where NIND is the sample size of grm.id
G1 is the first matrix
G2 is the second matrix
Out is the name of the interaction matrix

```
NIND=24287
G1=$'analysis_sample_north'
G2=$'traumaPCresid_north'
Out=$'GxTRAUMA_PCresid_north'

./HadamardP $NIND $G1 $G2 $Out > $Out.log

## WARNING
## For Nind>>> the grm.N.bin file might be problematic, copy from G or E matrix:
## cp $G1.grm.N.bin GxE_$Out.grm.N.bin

```
To create the interaction matrices

```
./RunHadamardP_north.sh

```
We need to copy the GRM.grm.N.bin files and save as GxTrauma2.grm.N.bin files - following warning provided by Carmen

```
cp analysis_sample_north.grm.N.bin GxTRAUMA_PCresid_north.grm.N.bin

cp analysis_sample_midnorth.grm.N.bin GxTRAUMA_PCresid_midnorth.grm.N.bin

cp analysis_sample_midsouth.grm.N.bin GxTRAUMA_PCresid_midsouth.grm.N.bin

cp analysis_sample_southwest.grm.N.bin GxTRAUMA_PCresid_southwest.grm.N.bin

cp analysis_sample_southeast.grm.N.bin GxTRAUMA_PCresid_southeast.grm.N.bin

```

Create a text file listing the pathway to the different relationship matrices  

```
vi mgrm_GxE_north.txt

```
By typing 'i' (for insert) I add the following paths

```
../traumaPCresid_files/analysis_sample_north

../traumaPCresid_files/traumaPCresid_north

../traumaPCresid_files/GxTRAUMA_PCresid_north

```
To save and quite, press the 'esc' button and type 'wq' (write quit). 

Run the reml analysis

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, MAY 2021
# Eddie UKB VCA Script

#$ -N cidi_gxe_PCresid_h2
#$ -cwd
#$ -pe sharedmem 10 # number of cores
#$ -l h_vmem=16G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

gcta64 --mgrm mgrm_GxE_north.txt --reml --pheno ../cidi.phen --out h2_cidi_GxE_PCresid_n --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/north_q_cov --covar ../../../grm/full_sample_grms/pca_full/north_cov --reml-lrt 3 --reml-est-fix  

gcta64 --mgrm mgrm_GxE_midnorth.txt --reml --pheno ../cidi.phen --out h2_cidi_GxE_PCresid_mn --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/midnorth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midnorth_cov --reml-lrt 3 --reml-est-fix

gcta64 --mgrm mgrm_GxE_midsouth.txt  --reml --pheno ../cidi.phen --out h2_cidi_GxE_PCresid_ms --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/midsouth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midsouth_cov --reml-lrt 3 --reml-est-fix

gcta64 --mgrm mgrm_GxE_southwest.txt  --reml --pheno ../cidi.phen --out h2_cidi_GxE_PCresid_sw --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/southwest_q_cov --covar ../../../grm/full_sample_grms/pca_full/southwest_cov --reml-lrt 3 --reml-est-fix

gcta64 --mgrm mgrm_GxE_southeast.txt   --reml --pheno ../cidi.phen --out h2_cidi_GxE_PCresid_se --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/southeast_q_cov --covar ../../../grm/full_sample_grms/pca_full/southeast_cov --reml-lrt 3 --reml-est-fix

```

















### Trauma PC1 (or PC2, PC3)  

Remember that I also want to explore PC2 and PC3 separately, the same script can be utilised except will substitute the trauma PC1 files to the relevant trauma PC files
  
Run the reml analysis (Model 2)  

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, MAY 2021
# Eddie UKB VCA Script

#$ -N cidi_ermPC1_reml
#$ -cwd
#$ -pe sharedmem 10 # number of cores
#$ -l h_vmem=16G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

gcta64 --grm ../../erm_traumaPC1/traumaPC1_north --reml --pheno ../cidi.phen --out h2_cidi_ermPC1_n --prevalence 0.28 --thread-num 10  --qcovar ../../../grm/full_sample_grms/pca_full/north_q_cov --covar ../../../grm/full_sample_grms/pca_full/north_cov --reml-est-fix  

gcta64 --grm ../../erm__traumaPC1/traumaPC1_midnorth --reml --pheno ../cidi.phen --out h2_cidi_ermPC1_mn --prevalence 0.28 --thread-num 10 --qcovar ../../../grm/full_sample_grms/pca_full/midnorth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midnorth_cov --reml-est-fix

gcta64 --grm ../../erm_traumaPC1/traumaPC1_midsouth --reml --pheno ../cidi.phen --out h2_cidi_ermPC1_ms --prevalence 0.28 --thread-num 10 --qcovar ../../../grm/full_sample_grms/pca_full/midsouth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midsouth_cov --reml-est-fix

gcta64 --grm ../../erm__traumaPC1/traumaPC1_southwest --reml --pheno ../cidi.phen --out h2_cidi_ermPC1_sw --prevalence 0.28 --thread-num 10 --qcovar ../../../grm/full_sample_grms/pca_full/southwest_q_cov --covar ../../../grm/full_sample_grms/pca_full/southwest_cov --reml-est-fix

gcta64 --grm ../../erm_traumaPC1/traumaPC1_southeast --reml --pheno ../cidi.phen --out h2_cidi_ermPC1_se --prevalence 0.28 --thread-num 10 --qcovar ../../../grm/full_sample_grms/pca_full/southeast_q_cov --covar ../../../grm/full_sample_grms/pca_full/southeast_cov --reml-est-fix

```
Run REML analysis (Model 3)  

Will create a txt file detailing the paths of the GRM and ERM

```
vi mgrm_G+E_north.txt
```
By typing 'i' (for insert) I add the following paths

```
../../erm_traumaPC1/traumaPC1_north
../../../grm/full_sample_grms/analysis_sample_north

```
To save and quite, press the 'esc' button and type 'wq' (write quit). 

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, MAY 2021
# Eddie UKB VCA Script

#$ -N cidi_g+e_PC1_h2_bK
#$ -cwd
#$ -pe sharedmem 10 # number of cores
#$ -l h_vmem=16G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

gcta64 --mgrm mgrm_G+E_north.txt --reml --pheno ../cidi.phen --out h2_cidi_G+E_PC1_n --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/north_q_cov --covar ../../../grm/full_sample_grms/pca_full/north_cov --reml-lrt 1 --reml-est-fix  

gcta64 --mgrm mgrm_G+E_midnorth.txt --reml --pheno ../cidi.phen --out h2_cidi_G+E_PC1_mn --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/midnorth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midnorth_cov --reml-lrt 1 --reml-est-fix

gcta64 --mgrm mgrm_G+E_midsouth.txt  --reml --pheno ../cidi.phen --out h2_cidi_G+E_PC1_ms --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/midsouth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midsouth_cov --reml-lrt 1 --reml-est-fix

gcta64 --mgrm mgrm_G+E_southwest.txt  --reml --pheno ../cidi.phen --out h2_cidi_G+E_PC1_sw --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/southwest_q_cov --covar ../../../grm/full_sample_grms/pca_full/southwest_cov --reml-lrt 1 --reml-est-fix

gcta64 --mgrm mgrm_G+E_southeast.txt   --reml --pheno ../cidi.phen --out h2_cidi_G+E_PC1_se --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/southeast_q_cov --covar ../../../grm/full_sample_grms/pca_full/southeast_cov --reml-lrt 1 --reml-est-fix

```
Run REML analysis (Model 4)  

I create a shell script (code provided by Carmen Amador) to specify which matrices to use for the final interaction matrix  

Where NIND is the sample size of grm.id
G1 is the first matrix
G2 is the second matrix
Out is the name of the interaction matrix

```
NIND=24287
G1=$'analysis_sample_north'
G2=$'traumaPC1_north'
Out=$'GxTRAUMA_PC1_north'

./HadamardP $NIND $G1 $G2 $Out > $Out.log

## WARNING
## For Nind>>> the grm.N.bin file might be problematic, copy from G or E matrix:
## cp $G1.grm.N.bin GxE_$Out.grm.N.bin

```
To create the interaction matrices

```
./RunHadamardP_north.sh

```
We need to copy the GRM.grm.N.bin files and save as GxTrauma2.grm.N.bin files - following warning provided by Carmen

```
cp analysis_sample_north.grm.N.bin GxTRAUMA_PC1_north.grm.N.bin

cp analysis_sample_midnorth.grm.N.bin GxTRAUMA_PC1_midnorth.grm.N.bin

cp analysis_sample_midsouth.grm.N.bin GxTRAUMA_PC1_midsouth.grm.N.bin

cp analysis_sample_southwest.grm.N.bin GxTRAUMA_PC1_southwest.grm.N.bin

cp analysis_sample_southeast.grm.N.bin GxTRAUMA_PC1_southeast.grm.N.bin


```
Create a text file listing the pathway to the different relationship matrices  

```
vi mgrm_GxE_north.txt

```
By typing 'i' (for insert) I add the following paths

```
../traumaPC1_files/analysis_sample_north

../traumaPC1_files/traumaPC1_north

../traumaPC1_files/GxTRAUMA_PC1_north

```
To save and quite, press the 'esc' button and type 'wq' (write quit). 

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, MAY 2021
# Eddie UKB VCA Script

#$ -N cidi_gxe_PC1_h2
#$ -cwd
#$ -pe sharedmem 10 # number of cores
#$ -l h_vmem=16G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

gcta64 --mgrm mgrm_GxE_north.txt --reml --pheno ../cidi.phen --out h2_cidi_GxE_PC1_n --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/north_q_cov --covar ../../../grm/full_sample_grms/pca_full/north_cov --reml-lrt 3 --reml-est-fix  

gcta64 --mgrm mgrm_GxE_midnorth.txt --reml --pheno ../cidi.phen --out h2_cidi_GxE_PC1_mn --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/midnorth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midnorth_cov --reml-lrt 3 --reml-est-fix

gcta64 --mgrm mgrm_GxE_midsouth.txt  --reml --pheno ../cidi.phen --out h2_cidi_GxE_PC1_ms --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/midsouth_q_cov --covar ../../../grm/full_sample_grms/pca_full/midsouth_cov --reml-lrt 3 --reml-est-fix

gcta64 --mgrm mgrm_GxE_southwest.txt  --reml --pheno ../cidi.phen --out h2_cidi_GxE_PC1_sw --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/southwest_q_cov --covar ../../../grm/full_sample_grms/pca_full/southwest_cov --reml-lrt 3 --reml-est-fix

gcta64 --mgrm mgrm_GxE_southeast.txt   --reml --pheno ../cidi.phen --out h2_cidi_GxE_PC1_se --thread-num 10 --prevalence 0.28 --qcovar ../../../grm/full_sample_grms/pca_full/southeast_q_cov --covar ../../../grm/full_sample_grms/pca_full/southeast_cov --reml-lrt 3 --reml-est-fix

```













### All Trauma Matrices (TRAUMA, CT, AT, CAT)  

creating the mgrm.txt file  

```
../../grm/full_sample_grms/analysis_sample_north

../subtrauma_erm/CT_north_allcomp
../subtrauma_erm/AT_north_allcomp
../subtrauma_erm/CAT_north_allcomp

../subtrauma_int/CT_int_north_allcomp
../subtrauma_int/AT_int_north_allcomp
../subtrauma_int/CAT_int_north_allcomp

```
Run REML Analysis  

```
#!/bin/sh
###########################################

# M.Chuong, Edinburgh U.K, MAY 2021
# Eddie UKB VCA Script

#$ -N cidi_allrm_reml
#$ -cwd
#$ -pe sharedmem 15 # number of cores
#$ -l h_vmem=16G # memory per core
#$ -l h_rt=48:00:00 ## requested time
#$ -m baes ## notifications: (b)begin/(a)aborted/(e)end/(s)suspended/(n)nomail
#$ -M melisa.chuong@ed.ac.uk ## email for notifications

# INITIALISE ENV MODULES
. /etc/profile.d/modules.sh # if using modules need to add this line

# LOAD THE MODULES
module load igmm/apps/gcta/1.91.4beta 

# CREATING NEW BINARY PLINK FILES TO CREATE GRMs

gcta64 --mgrm mgrm_GxE_north.txt --reml --pheno ../../grm/cidi.phen --out h2_cidi_all_rm_n --prevalence 0.28 --thread-num 15  --qcovar ../../grm/full_sample_grms/pca_full/north_q_cov --covar ../../grm/full_sample_grms/pca_full/north_cov --reml-est-fix

gcta64 --mgrm mgrm_GxE_midnorth.txt --reml --pheno ../../grm/cidi.phen --out h2_cidi_all_rm_mn --prevalence 0.28 --thread-num 15 --qcovar ../../grm/full_sample_grms/pca_full/midnorth_q_cov --covar ../../grm/full_sample_grms/pca_full/midnorth_cov --reml-est-fix

gcta64 --mgrm mgrm_GxE_midsouth.txt --reml --pheno ../../grm/cidi.phen --out h2_cidi_all_rm_ms --prevalence 0.28 --thread-num 15 --qcovar ../../grm/full_sample_grms/pca_full/midsouth_q_cov --covar ../../grm/full_sample_grms/pca_full/midsouth_cov --reml-est-fix

gcta64 --mgrm mgrm_GxE_southwest.txt --reml --pheno ../../grm/cidi.phen --out h2_cidi_all_rm_sw --prevalence 0.28 --thread-num 15 --qcovar ../../grm/full_sample_grms/pca_full/southwest_q_cov --covar ../../grm/full_sample_grms/pca_full/southwest_cov --reml-est-fix

gcta64 --mgrm mgrm_GxE_southeast.txt --reml --pheno ../../grm/cidi.phen --out h2_cidi_all_rm_se --prevalence 0.28 --thread-num 15 --qcovar ../../grm/full_sample_grms/pca_full/southeast_q_cov --covar ../../grm/full_sample_grms/pca_full/southeast_cov --reml-est-fix

```
Collate all relevant information  

```{r, eval=FALSE}
#broad

rm(list=ls())
ov <- as.data.frame(matrix(NA, nrow=17, ncol=1)) #creating a dataframe ov, overview
ov[,1] <- c("VG", "Vct", "Vat", "Vcat", "Vctint", "Vatint", "Vcatint", "VE", "VP", "H2_GRM", "H2_CT", "H2_AT", "H2_CAT", "H2CTINT", "H2ATINT", "H2CATINT", "H2_SUM")

for(cluster in c("n", "mn", "ms", "sw", "sw")){
  
  hsq <- read.delim(paste0("h2_broad_all_rm_", cluster, ".hsq"))
  hsq_info <- hsq[c(1:9, 20:26, 27), 2:3]
  ov <- cbind(ov, hsq_info)
  
  }

write.csv(ov, "broad_allRM_VCA_info.csv", row.names=F, quote=F)

#cidi

rm(list=ls())
ov <- as.data.frame(matrix(NA, nrow=17, ncol=1)) #creating a dataframe ov, overview
ov[,1] <- c("VG", "Vct", "Vat", "Vcat", "Vctint", "Vatint", "Vcatint", "VE", "VP", "H2_GRM", "H2_CT", "H2_AT", "H2_CAT", "H2CTINT", "H2ATINT", "H2CATINT", "H2_SUM")

for(cluster in c("n", "mn", "ms", "sw", "sw")){
  
  hsq <- read.delim(paste0("h2_cidi_all_rm_", cluster, ".hsq"))
  hsq_info <- hsq[c(1:9, 20:26, 27), 2:3]
  ov <- cbind(ov, hsq_info)
  
  }

write.csv(ov, "cidi_allRM_VCA_info.csv", row.names=F, quote=F)

#neuro

rm(list=ls())
ov <- as.data.frame(matrix(NA, nrow=17, ncol=1)) #creating a dataframe ov, overview
ov[,1] <- c("VG", "Vct", "Vat", "Vcat", "Vctint", "Vatint", "Vcatint", "VE", "VP", "H2_GRM", "H2_CT", "H2_AT", "H2_CAT", "H2CTINT", "H2ATINT", "H2CATINT", "H2_SUM")

for(cluster in c("mn", "ms", "sw", "sw")){
  
  hsq <- read.delim(paste0("h2_neuro_all_rm_", cluster, ".hsq"))
  hsq_info <- hsq[1:17, 2:3]
  ov <- cbind(ov, hsq_info)
  
  }

write.csv(ov, "neuro_allRM_VCA_info.csv", row.names=F, quote=F)

```

### Meta-analyses  

As analyses are replicated across different clusters, we need to meta-analyse results  

```{r, eval = FALSE}
 
# This is a semi-automatic script, file paths need to be changed accordingly  

                ####################################################
                # SINGLE RANDOM EFFECT (AKA 1 RELATIONSHIP MATRIX) #
                ####################################################

# Will be using 'metafor' package to run the meta-analyses
# We will be using a fixed-effects model using the inverse-variance weighting formula

library(metafor)

# Remember we can have different samples e.g. Full, Unrelated, Female, Male
# Remember we can have different models e.g. GRM, ERM, G+E, G+E+GxE
# Remember we can have different forms of ERMs e.g. 16traumaPCs, 1traumaPC, traumaPCresidualised, ct, at, cat

rm(list=ls())

sample <- "UNRELATED_FEMALE" #remember to change this when looking at different samples
model <- "ERM" #remember to change this when looking at different models
E <- "TRAUMA"

# Will be using different scripts for broad & cidi depression as these are converted to the liability scale

    for (depvar in c("broad", "cidi")){
    
    # creating a df with 3 columns; prefix (aka cluster), variance (aka beta estimate), SE (standard error)
    ov <- as.data.frame(matrix(NA, nrow=1, ncol=3))
    colnames(ov) <- c("prefix", "Variance", "SE")
    
    for(prefix in c("n", "mn", "ms", "sw", "se")){ #clusters
      
      #below I read in the REML analysis output for the specific cluster and DV
      hsq <- read.delim(paste0("../erm/reml_full/SexSpecific_unrelated/h2_female_", depvar, "_erm_", prefix, ".hsq"))
      
      #below I extract the H2 (aka the proportion of variance accounted for by the relationship matrix) from the result output
      #the file obtains the cluster, beta estimate(variance) and SE values
      hsq_info <- cbind(prefix, hsq[7,2:3])
      ov <- rbind(ov, hsq_info)
    }
    ov <- ov[-1,] #removing the NA rows which were formed when creating the DF
    
    #now I will run the meta-analysis, below I specify the type of data we will be meta-analysing (yi for estimates, sei for standard errors)
    dat <- escalc(measure="RR", yi=Variance, sei=SE, data=ov)
    
    #running the fixed effects meta-analysis using inverse-variance weighting!
    meta <- summary(rma.uni(as.numeric(yi), as.numeric(vi), method="FE", data=dat))
    
    #combining info on the sample, model, variance component, DV, and the meta-analyses proportion of variance
    meta_info <- cbind(sample, model, "GRM", E, depvar, meta$beta, meta$se, meta$pval, meta$ci.lb, meta$ci.ub)
    colnames(meta_info) <- c("SAMPLE", "MODEL", "VARCOMP", "E", "DV", "METAH2", "METASE", "METAPVAL", "METACIlb", "METACIub")  
 
    #should aim to make resulting file as informative as possible!   
    write.csv(meta_info, paste0(depvar, "_", sample, "_", model, "_", E, "_meta_VCA_info.csv"), row.names=F)
  
    }
    
# Scripts will be slightly different for neuroticisim results as this is not converted to the liability scale (continuous trait), so row numbers are slightly different

    depvar <- "neuro"
    
    ov <- as.data.frame(matrix(NA, nrow=1, ncol=3))
    colnames(ov) <- c("prefix", "Variance", "SE")
    
    for(prefix in c("n", "mn", "ms", "sw", "se")){ #clusters
      hsq <- read.delim(paste0("../erm/reml_full/SexSpecific_unrelated/h2_female_", depvar, "_erm_", prefix, ".hsq"))
      hsq_info <- cbind(prefix, hsq[4,2:3]) #row 4 is what we need!
      ov <- rbind(ov, hsq_info)
    }
    
    ov <- ov[-1,] 
    
    dat <- escalc(measure="RR", yi=Variance, sei=SE, data=ov)
    meta <- summary(rma.uni(as.numeric(yi), as.numeric(vi), method="FE", data=dat))
    meta_info <- cbind(sample, model, "GRM", E, depvar, meta$beta, meta$se, meta$pval, meta$ci.lb, meta$ci.ub)
    colnames(meta_info) <- c("SAMPLE", "MODEL", "VARCOMP", "E", "DV", "METAH2", "METASE", "METAPVAL", "METACIlb", "METACIub")  
    
    write.csv(meta_info, paste0(depvar, "_",  sample, "_", model, "_", E, "_meta_VCA_info.csv"), row.names=F)
  
                ####################################################
                # TWO RANDOM EFFECTS (AKA 2 RELATIONSHIP MATRICES) #
                ####################################################    
    
    library(metafor)
    
    # Remember we can have different samples e.g. Full, Unrelated, Female, Male
    # Remember we can have different models e.g. GRM, ERM, G+E, G+E+GxE
    # Remember we can have different forms of ERMs e.g. 16traumaPCs, 1traumaPC, traumaPCresidualised, ct, at, cat
    
    rm(list=ls())
    
    sample <- "UNRELATED_MALE" #remember to change this when looking at different samples
    model <- "G+E" #remember to change this when looking at different models
    E <- "TRAUMAPC"
    
# Will be using different scripts for broad & cidi depression as these are converted to the liability scale
    
    for (depvar in c("broad", "cidi")){
      
      # creating a df with 3 columns; prefix (aka cluster), variance (aka beta estimate), SE (standard error)
      ov <- as.data.frame(matrix(NA, nrow=1, ncol=4))
      colnames(ov) <- c("prefix", "VARCOMP", "Variance", "SE")
      
      for(prefix in c("n", "mn", "ms", "sw", "se")){ #clusters
        
        #below I read in the REML analysis output for the specific cluster and DV
        hsq <- read.delim(paste0("../erm/reml_G+E/SexSpecific_unrelated/h2_male_", depvar, "_G+E_", prefix, ".hsq"))
        
        #below I extract the H2 (aka the proportion of variance accounted for by the relationship matrices) from the result output
        #the file obtains the cluster, beta estimate(variance) and SE values
        hsq_E <- cbind(prefix, "ERM", hsq[10,2:3])
        colnames(hsq_E)[2] <- "VARCOMP"
        hsq_G <- cbind(prefix, "GRM",  hsq[11,2:3])
        colnames(hsq_G)[2] <- "VARCOMP"
        
        ov <- Reduce(function(x,y) rbind(x=x,y=y), list(ov, hsq_E, hsq_G))
      }
      ov <- ov[-1,] #removing the NA rows which were formed when creating the DF
      
      #subsetting based on variance components!
      ov1 <- subset(ov, ov$VARCOMP=="GRM")
      ov2 <- subset(ov, ov$VARCOMP=="ERM")
      
      #now I will run the meta-analysis, below I specify the type of data we will be meta-analysing (yi for estimates, sei for standard errors)
      dat1 <- escalc(measure="RR", yi=Variance, sei=SE, data=ov1) #GRM
      dat2 <- escalc(measure="RR", yi=Variance, sei=SE, data=ov2) #ERM
      
      #running the fixed effects meta-analysis using inverse-variance weighting!
      meta1 <- summary(rma.uni(as.numeric(yi), as.numeric(vi), method="FE", data=dat1))
      meta2 <- summary(rma.uni(as.numeric(yi), as.numeric(vi), method="FE", data=dat2))
      
      #combining info on the sample, model, variance component, DV, and the meta-analyses proportion of variance
      meta1_info <- cbind(sample, model, "GRM", E, depvar, meta1$beta, meta1$se, meta1$pval, meta1$ci.lb, meta1$ci.ub)
      colnames(meta1_info) <- c("SAMPLE", "MODEL", "VARCOMP", "E", "DV", "METAH2", "METASE", "METAPVAL", "METACIlb", "METACIub")  

      meta2_info <- cbind(sample, model, "ERM", E, depvar, meta2$beta, meta2$se, meta2$pval, meta2$ci.lb, meta2$ci.ub)
      colnames(meta2_info) <- c("SAMPLE", "MODEL", "VARCOMP", "E", "DV", "METAH2", "METASE", "METAPVAL", "METACIlb", "METACIub")  
      
      meta_info <- rbind(meta1_info, meta2_info)
      
      #should aim to make resulting file as informative as possible!   
      write.csv(meta_info, paste0(depvar, "_", sample, "_", model, "_", E, "_meta_VCA_info.csv"), row.names=F)
      
    }
    
# Scripts will be slightly different for neuroticisim results as this is not converted to the liability scale (continuous trait), so row numbers are slightly different
    
      depvar <- "neuro"
      
      # creating a df with 3 columns; prefix (aka cluster), variance (aka beta estimate), SE (standard error)
      ov <- as.data.frame(matrix(NA, nrow=1, ncol=4))
      colnames(ov) <- c("prefix", "VARCOMP", "Variance", "SE")
      
      for(prefix in c("mn", "ms", "sw", "se")){ #clusters
        
        #below I read in the REML analysis output for the specific cluster and DV
        hsq <- read.delim(paste0("../erm/reml_G+E/SexSpecific_unrelated/h2_male_", depvar, "_G+E_", prefix, ".hsq"))
        
        #below I extract the H2 (aka the proportion of variance accounted for by the relationship matrices) from the result output
        #the file obtains the cluster, beta estimate(variance) and SE values
        hsq_E <- cbind(prefix, "ERM", hsq[5,2:3])
        colnames(hsq_E)[2] <- "VARCOMP"
        hsq_G <- cbind(prefix, "GRM",  hsq[6,2:3])
        colnames(hsq_G)[2] <- "VARCOMP"
        
        ov <- Reduce(function(x,y) rbind(x=x,y=y), list(ov, hsq_E, hsq_G))
      }
      ov <- ov[-1,] #removing the NA rows which were formed when creating the DF
      
      #subsetting based on variance components!
      ov1 <- subset(ov, ov$VARCOMP=="GRM")
      ov2 <- subset(ov, ov$VARCOMP=="ERM")
      
      #now I will run the meta-analysis, below I specify the type of data we will be meta-analysing (yi for estimates, sei for standard errors)
      dat1 <- escalc(measure="RR", yi=Variance, sei=SE, data=ov1) #GRM
      dat2 <- escalc(measure="RR", yi=Variance, sei=SE, data=ov2) #ERM
      
      #running the fixed effects meta-analysis using inverse-variance weighting!
      meta1 <- summary(rma.uni(as.numeric(yi), as.numeric(vi), method="FE", data=dat1))
      meta2 <- summary(rma.uni(as.numeric(yi), as.numeric(vi), method="FE", data=dat2))
      
      #combining info on the sample, model, variance component, DV, and the meta-analyses proportion of variance
      meta1_info <- cbind(sample, model, "GRM", E, depvar, meta1$beta, meta1$se, meta1$pval, meta1$ci.lb, meta1$ci.ub)
      colnames(meta1_info) <- c("SAMPLE", "MODEL", "VARCOMP", "E", "DV", "METAH2", "METASE", "METAPVAL", "METACIlb", "METACIub")  
      
      meta2_info <- cbind(sample, model, "ERM", E, depvar, meta2$beta, meta2$se, meta2$pval, meta2$ci.lb, meta2$ci.ub)
      colnames(meta2_info) <- c("SAMPLE", "MODEL", "VARCOMP", "E", "DV", "METAH2", "METASE", "METAPVAL", "METACIlb", "METACIub")  
      
      meta_info <- rbind(meta1_info, meta2_info)
      
      #should aim to make resulting file as informative as possible!   
      write.csv(meta_info, paste0(depvar, "_", sample, "_", model, "_", E, "_meta_VCA_info.csv"), row.names=F)

      ######################################################
      # THREE RANDOM EFFECTS (AKA 3 RELATIONSHIP MATRICES) #
      ######################################################   
      
      library(metafor)
      
      # Remember we can have different samples e.g. Full, Unrelated, Female, Male
      # Remember we can have different models e.g. GRM, ERM, G+E, G+E+GxE
      # Remember we can have different forms of ERMs e.g. 16traumaPCs, 1traumaPC, traumaPCresidualised, ct, at, cat
      
      rm(list=ls())
      
      sample <- "UNRELATED_FEMALE" #remember to change this when looking at different samples
      model <- "GxE" #remember to change this when looking at different models
      E <- "TRAUMAPC"
      
# Will be using different scripts for broad & cidi depression as these are converted to the liability scale
      for (depvar in c("broad", "cidi")){
        
        # creating a df with 3 columns; prefix (aka cluster), variance (aka beta estimate), SE (standard error)
        ov <- as.data.frame(matrix(NA, nrow=1, ncol=4))
        colnames(ov) <- c("prefix", "VARCOMP", "Variance", "SE")
        
        for(prefix in c("n", "mn", "ms", "sw", "se")){ #clusters
          
          #below I read in the REML analysis output for the specific cluster and DV
          hsq <- read.delim(paste0("../erm/reml_GxE/SexSpecific_unrelated/h2_female_", depvar, "_GxE_", prefix, ".hsq"))
          
          #below I extract the H2 (aka the proportion of variance accounted for by the relationship matrices) from the result output
          #the file obtains the cluster, beta estimate(variance) and SE values
          hsq_G <- cbind(prefix, "GRM", hsq[12,2:3])
          colnames(hsq_G)[2] <- "VARCOMP"
          hsq_E <- cbind(prefix, "ERM",  hsq[13,2:3])
          colnames(hsq_E)[2] <- "VARCOMP"
          hsq_GE <- cbind(prefix, "GxE",  hsq[14,2:3])
          colnames(hsq_GE)[2] <- "VARCOMP"
          
          ov <- Reduce(function(x,y) rbind(x=x,y=y), list(ov, hsq_G, hsq_E, hsq_GE))
        }
        ov <- ov[-1,] #removing the NA rows which were formed when creating the DF
        
        #subsetting based on variance components!
        ov1 <- subset(ov, ov$VARCOMP=="GRM")
        ov2 <- subset(ov, ov$VARCOMP=="ERM")
        ov3 <- subset(ov, ov$VARCOMP=="GxE")
        
        #now I will run the meta-analysis, below I specify the type of data we will be meta-analysing (yi for estimates, sei for standard errors)
        dat1 <- escalc(measure="RR", yi=Variance, sei=SE, data=ov1) #GRM
        dat2 <- escalc(measure="RR", yi=Variance, sei=SE, data=ov2) #ERM
        dat3 <- escalc(measure="RR", yi=Variance, sei=SE, data=ov3) #GRMxERM
        
        #running the fixed effects meta-analysis using inverse-variance weighting!
        meta1 <- summary(rma.uni(as.numeric(yi), as.numeric(vi), method="FE", data=dat1))
        meta2 <- summary(rma.uni(as.numeric(yi), as.numeric(vi), method="FE", data=dat2))
        meta3 <- summary(rma.uni(as.numeric(yi), as.numeric(vi), method="FE", data=dat3))
        
        #combining info on the sample, model, variance component, DV, and the meta-analyses proportion of variance
        meta1_info <- cbind(sample, model, "GRM", E, depvar, meta1$beta, meta1$se, meta1$pval, meta1$ci.lb, meta1$ci.ub)
        colnames(meta1_info) <- c("SAMPLE", "MODEL", "VARCOMP", "E", "DV", "METAH2", "METASE", "METAPVAL", "METACIlb", "METACIub")  
        
        meta2_info <- cbind(sample, model, "ERM", E, depvar, meta2$beta, meta2$se, meta2$pval, meta2$ci.lb, meta2$ci.ub)
        colnames(meta2_info) <- c("SAMPLE", "MODEL", "VARCOMP", "E", "DV", "METAH2", "METASE", "METAPVAL", "METACIlb", "METACIub")  

        meta3_info <- cbind(sample, model, "GxE", E, depvar, meta3$beta, meta3$se, meta3$pval, meta3$ci.lb, meta3$ci.ub)
        colnames(meta3_info) <- c("SAMPLE", "MODEL", "VARCOMP", "E", "DV", "METAH2", "METASE", "METAPVAL", "METACIlb", "METACIub")  
        
        meta_info <- Reduce(function(x,y) rbind(x=x,y=y), list(meta1_info, meta2_info, meta3_info))
        
        #should aim to make resulting file as informative as possible!   
        write.csv(meta_info, paste0(depvar, "_", sample, "_", model, "_", E, "_meta_VCA_info.csv"), row.names=F)
        
      }

# Scripts will be slightly different for neuroticisim results as this is not converted to the liability scale (continuous trait), so row numbers are slightly different
      
      depvar <- "neuro"
        
        # creating a df with 3 columns; prefix (aka cluster), variance (aka beta estimate), SE (standard error)
        ov <- as.data.frame(matrix(NA, nrow=1, ncol=4))
        colnames(ov) <- c("prefix", "VARCOMP", "Variance", "SE")
        
        for(prefix in c("n", "mn", "ms", "sw", "se")){ #clusters
          
          #below I read in the REML analysis output for the specific cluster and DV
          hsq <- read.delim(paste0("../erm/reml_GxE/SexSpecific_unrelated/h2_female_", depvar, "_GxE_", prefix, ".hsq"))
          
          #below I extract the H2 (aka the proportion of variance accounted for by the relationship matrices) from the result output
          #the file obtains the cluster, beta estimate(variance) and SE values
          hsq_G <- cbind(prefix, "GRM", hsq[6,2:3])
          colnames(hsq_G)[2] <- "VARCOMP"
          hsq_E <- cbind(prefix, "ERM",  hsq[7,2:3])
          colnames(hsq_E)[2] <- "VARCOMP"
          hsq_GE <- cbind(prefix, "GxE",  hsq[8,2:3])
          colnames(hsq_GE)[2] <- "VARCOMP"
          
          ov <- Reduce(function(x,y) rbind(x=x,y=y), list(ov, hsq_G, hsq_E, hsq_GE))
        }
        ov <- ov[-1,] #removing the NA rows which were formed when creating the DF
        
        #subsetting based on variance components!
        ov1 <- subset(ov, ov$VARCOMP=="GRM")
        ov2 <- subset(ov, ov$VARCOMP=="ERM")
        ov3 <- subset(ov, ov$VARCOMP=="GxE")
        
        #now I will run the meta-analysis, below I specify the type of data we will be meta-analysing (yi for estimates, sei for standard errors)
        dat1 <- escalc(measure="RR", yi=Variance, sei=SE, data=ov1) #GRM
        dat2 <- escalc(measure="RR", yi=Variance, sei=SE, data=ov2) #ERM
        dat3 <- escalc(measure="RR", yi=Variance, sei=SE, data=ov3) #GRMxERM
        
        #running the fixed effects meta-analysis using inverse-variance weighting!
        meta1 <- summary(rma.uni(as.numeric(yi), as.numeric(vi), method="FE", data=dat1))
        meta2 <- summary(rma.uni(as.numeric(yi), as.numeric(vi), method="FE", data=dat2))
        meta3 <- summary(rma.uni(as.numeric(yi), as.numeric(vi), method="FE", data=dat3))
        
        #combining info on the sample, model, variance component, DV, and the meta-analyses proportion of variance
        meta1_info <- cbind(sample, model, "GRM", E, depvar, meta1$beta, meta1$se, meta1$pval, meta1$ci.lb, meta1$ci.ub)
        colnames(meta1_info) <- c("SAMPLE", "MODEL", "VARCOMP", "E", "DV", "METAH2", "METASE", "METAPVAL", "METACIlb", "METACIub")  
        
        meta2_info <- cbind(sample, model, "ERM", E, depvar, meta2$beta, meta2$se, meta2$pval, meta2$ci.lb, meta2$ci.ub)
        colnames(meta2_info) <- c("SAMPLE", "MODEL", "VARCOMP", "E", "DV", "METAH2", "METASE", "METAPVAL", "METACIlb", "METACIub")  
        
        meta3_info <- cbind(sample, model, "GxE", E, depvar, meta3$beta, meta3$se, meta3$pval, meta3$ci.lb, meta3$ci.ub)
        colnames(meta3_info) <- c("SAMPLE", "MODEL", "VARCOMP", "E", "DV", "METAH2", "METASE", "METAPVAL", "METACIlb", "METACIub")  
        
        meta_info <- Reduce(function(x,y) rbind(x=x,y=y), list(meta1_info, meta2_info, meta3_info))
        
        #should aim to make resulting file as informative as possible!   
        write.csv(meta_info, paste0(depvar, "_", sample, "_", model, "_", E, "_meta_VCA_info.csv"), row.names=F)
        
```

### Collate Results  

I want to extract and collate all the important estimates from the MLM analyses. I have 5 different clusters, so each analysis is replicated 5 times. More importantly, depending on the model, the number of estimates that are important changes. Results are outputted into files with prefix .hsq  

The following script will work from Model 1 and Model 2 results - here we need to change the name of the hsq file to keep in line with the files we are interested in.  

```{r, eval=FALSE}

# Here I have a semi-automated script
# I need to specify the sample and the what the ERM represents
# I also need to adjust the script with the relevant paths for the files 
# e.g. ../grm/full_sample_grms/analysis_sample would be the full sample GRMs

rm(list=ls())

sample <- "UNRELATED_MALE"
E <- "TRAUMA"

################################
#   CIDI & BROAD DEPRESSION    #   
################################

for(depvar in c("broad", "cidi")){
  for(prefix in c("n", "mn", "ms", "sw", "se")){

#creating a dataframe ov, overview file
ov <- as.data.frame(matrix(NA, nrow=1, ncol=5))
colnames(ov) <- c("prefix", "Variance", "SE", "LRT", "LRT-P")

# reading in GRM model results
Ghsq <- read.delim(paste0("../grm/reml_full/SexSpecific_unrelated/h2_male_", depvar, "_", prefix, ".hsq"))
Ghsq_info <- cbind(prefix, Ghsq[7,2:3], Ghsq[10,2], Ghsq[12,2])
colnames(Ghsq_info)[4:5] <- c("LRT", "LRT-P")

# reading in ERM model results
Ehsq <- read.delim(paste0("../erm/reml_full/SexSpecific_unrelated/h2_male_", depvar, "_erm_", prefix, ".hsq"))
Ehsq_info <- cbind(prefix, Ehsq[7,2:3], Ehsq[10,2], Ehsq[12,2])
colnames(Ehsq_info)[4:5] <- c("LRT", "LRT-P")

# reading in GRM + ERM model results
G_Ehsq <- read.delim(paste0("../erm/reml_G+E/SexSpecific_unrelated/h2_male_", depvar, "_G+E_", prefix, ".hsq"))
G_Ehsq_info1 <- cbind(prefix, G_Ehsq[11,2:3], NA, NA)
colnames(G_Ehsq_info1)[4:5] <- c("LRT", "LRT-P")
G_Ehsq_info2 <- cbind(prefix, G_Ehsq[10,2:3], G_Ehsq[15,2], G_Ehsq[17,2])
colnames(G_Ehsq_info2)[4:5] <- c("LRT", "LRT-P")
G_Ehsq_info <- rbind(G_Ehsq_info1, G_Ehsq_info2)

# reading in GRM + ERM + GRMxERM results
GxEhsq <- read.delim(paste0("../erm/reml_GxE/SexSpecific_unrelated/h2_male_", depvar, "_GxE_", prefix, ".hsq"))
GxEhsq_info1 <- cbind(prefix, GxEhsq[12,2:3], NA, NA)
colnames(GxEhsq_info1)[4:5] <- c("LRT", "LRT-P")
GxEhsq_info2 <- cbind(prefix, GxEhsq[13,2:3], NA, NA)
colnames(GxEhsq_info2)[4:5] <- c("LRT", "LRT-P")
GxEhsq_info3 <- cbind(prefix, GxEhsq[14,2:3], GxEhsq[18,2], GxEhsq[20,2])
colnames(GxEhsq_info3)[4:5] <- c("LRT", "LRT-P")
GxEhsq_info <- Reduce(function(x,y) rbind(x=x,y=y), list(GxEhsq_info1, GxEhsq_info2, GxEhsq_info3))

#combine all results
allinfo <- Reduce(function(x,y) rbind(x=x,y=y), list(Ghsq_info, Ehsq_info, G_Ehsq_info, GxEhsq_info))
write.csv(allinfo, paste0(sample, "_", E, "_", depvar, "_VCA_results_", prefix, ".csv"), row.names=F)
}}

################################
#         NEUROTICISM          #   
################################

depvar <- "neuro"

for(prefix in c("n", "mn", "ms", "sw", "se")){
    
#creating a dataframe ov, overview file
ov <- as.data.frame(matrix(NA, nrow=1, ncol=5))
colnames(ov) <- c("prefix", "Variance", "SE", "LRT", "LRT-P")
    
# reading in GRM model results
Ghsq <- read.delim(paste0("../grm/reml_full/SexSpecific_unrelated/h2_male_", depvar, "_", prefix, ".hsq"))
Ghsq_info <- cbind(prefix, Ghsq[4,2:3], Ghsq[7,2], Ghsq[9,2])
colnames(Ghsq_info)[4:5] <- c("LRT", "LRT-P")
    
# reading in ERM model results
Ehsq <- read.delim(paste0("../erm/reml_full/SexSpecific_unrelated/h2_male_", depvar, "_erm_", prefix, ".hsq"))
Ehsq_info <- cbind(prefix, Ehsq[4,2:3], Ehsq[7,2], Ehsq[9,2])
colnames(Ehsq_info)[4:5] <- c("LRT", "LRT-P")
  
# reading in GRM + ERM model results
G_Ehsq <- read.delim(paste0("../erm/reml_G+E/SexSpecific_unrelated/h2_male_", depvar, "_G+E_", prefix, ".hsq"))
G_Ehsq_info1 <- cbind(prefix, G_Ehsq[6,2:3], NA, NA)
colnames(G_Ehsq_info1)[4:5] <- c("LRT", "LRT-P")
G_Ehsq_info2 <- cbind(prefix, G_Ehsq[5,2:3], G_Ehsq[10,2], G_Ehsq[12,2])
colnames(G_Ehsq_info2)[4:5] <- c("LRT", "LRT-P")
G_Ehsq_info <- rbind(G_Ehsq_info1, G_Ehsq_info2)
    
# reading in GRM + ERM + GRMxERM results
GxEhsq <- read.delim(paste0("../erm/reml_GxE/SexSpecific_unrelated/h2_male_", depvar, "_GxE_", prefix, ".hsq"))
GxEhsq_info1 <- cbind(prefix, GxEhsq[6,2:3], NA, NA)
colnames(GxEhsq_info1)[4:5] <- c("LRT", "LRT-P")
GxEhsq_info2 <- cbind(prefix, GxEhsq[7,2:3], NA, NA)
colnames(GxEhsq_info2)[4:5] <- c("LRT", "LRT-P")
GxEhsq_info3 <- cbind(prefix, GxEhsq[8,2:3], GxEhsq[12,2], GxEhsq[14,2])
colnames(GxEhsq_info3)[4:5] <- c("LRT", "LRT-P")
GxEhsq_info <- Reduce(function(x,y) rbind(x=x,y=y), list(GxEhsq_info1, GxEhsq_info2, GxEhsq_info3))
    
# combine all results
allinfo <- Reduce(function(x,y) rbind(x=x,y=y), list(Ghsq_info, Ehsq_info, G_Ehsq_info, GxEhsq_info))
write.csv(allinfo, paste0(sample, "_", E, "_", depvar, "_VCA_results_", prefix, ".csv"), row.names=F)
}

################################
#    META-ANALYSED RESULTS     #   
################################

for(depvar in c("broad", "cidi", "neuro")){
  
# reading in GRM model results
grminfo <- read.csv(paste0("../meta_analyses/", depvar, "_", sample, "_GRM_", E, "_meta_VCA_info.csv"))
grm_info <- cbind("meta-A", grminfo[,6:8])
colnames(grm_info)[2:4] <- c("Variance", "SE", "P")

# reading in ERM model results
erminfo <- read.csv(paste0("../meta_analyses/", depvar, "_", sample, "_ERM_", E, "_meta_VCA_info.csv"))
erm_info <- cbind("meta-A", erminfo[,6:8])
colnames(erm_info)[2:4] <- c("Variance", "SE", "P")

# reading in GRM + ERM model results
G_Einfo <- read.csv(paste0("../meta_analyses/", depvar, "_", sample, "_G+E_", E, "_meta_VCA_info.csv"))
G_E_info <- cbind("meta-A", G_Einfo[1:2,6:8])
colnames(G_E_info)[2:4] <- c("Variance", "SE", "P")

# reading in GRM + ERM + GRMxERM model results
GxEinfo <- read.csv(paste0("../meta_analyses/", depvar, "_", sample, "_GxE_", E, "_meta_VCA_info.csv"))
GxE_info <- cbind("meta-A", GxEinfo[1:3,6:8])
colnames(GxE_info)[2:4] <- c("Variance", "SE", "P")

# combine all results

allinfo <- Reduce(function(x,y) rbind(x=x,y=y), list(grm_info, erm_info, G_E_info, GxE_info))
write.csv(allinfo, paste0(sample, "_", E, "_", depvar, "_meta_VCA_results.csv"), row.names=F)

}
```

### Figures  

I have all the meta-analysed results in separate .csv files, I need to collate these into a single dataframe which will be used when creating relevant plots  

```{r, eval=FALSE}
rm(list=ls())

df <- list.files(pattern = "*.csv") %>% 
      map_df(~read_csv(.))

df$VARCOMP[df$MODEL=="ERM"] <- "ERM"

df$E[df$E=="CT"] <- "CHILDHOOD TRAUMA"
df$E[df$E=="AT"] <- "ADULT TRAUMA"
df$E[df$E=="CAT"] <- "CATASTROPHIC TRAUMA"
df$E[df$E=="TRAUMA"] <- "FULL TRAUMA"
df$E <- factor(df$E, levels=c("FULL TRAUMA", "CHILDHOOD TRAUMA", "ADULT TRAUMA", "CATASTROPHIC TRAUMA"))

df$DV[df$DV=="cidi"] <- "CIDI DEPRESSION"
df$DV[df$DV=="broad"] <- "BROAD DEPRESSION"
df$DV[df$DV=="neuro"] <- "NEUROTICISM"
df$DV <- factor(df$DV, levels=c("CIDI DEPRESSION", "BROAD DEPRESSION", "NEUROTICISM"))

df$MODEL[df$MODEL=="GRM"] <- "G"
df$MODEL[df$MODEL=="ERM"] <- "E"
df$MODEL[df$MODEL=="GxE"] <- "G+E+GxE"

df$VARCOMP[df$VARCOMP=="GRM"] <- "G"
df$VARCOMP[df$VARCOMP=="ERM"] <- "E"

```

The first plot will compare MLM variance component results when using ERMs capturing trauma, catastrophic trauma, childhood trauma, adult trauma  

```{r, eval=FALSE}

library(ggplot2)

df2 <- df %>%
       filter(SAMPLE=="FULL", E=="FULL TRAUMA" | E=="CHILDHOOD TRAUMA" | E=="ADULT TRAUMA" | E=="CATASTROPHIC TRAUMA")

plot <- ggplot(data = df2, aes(x = factor(MODEL, levels = c("G", "E", "G+E", "G+E+GxE")), y = METAH2, fill = factor(VARCOMP, levels = c("GxE", "E", "G")))) + 
  geom_bar(stat="identity") + 
  scale_fill_brewer("Variance Components", palette="Dark2") + 
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.2)) + 
  facet_wrap(~E, ncol=4) + 
  facet_grid(DV~E) + 
  xlab("Mixed Linear Models") + ylab("Proportion of Variance") +
  theme_bw() +
  theme(axis.text.x=element_text(angle=45, hjust=1))

ggsave(file = "reml_trauma_comparisons.png", plot=plot, width=10, height=5)
ggsave(file = "reml_trauma_comparisons.svg", plot=plot, width=10, height=5)

```

The second plot will compare MLM variance components results when using ERMs capturing trauma (using trauma PC1, trauma PCs pre-corrected for the GRM)

```{r, eval=FALSE}

df3 <- df %>%
       filter(SAMPLE=="FULL", E=="TRAUMA" | E=="TRAUMAPCresid" | E=="TRAUMAPC1")
df3$E <- factor(df3$E, levels=c("TRAUMA", "TRAUMAPCresid", "TRAUMAPC1"))

PCresid_GRMs <- df3 %>%
                filter(SAMPLE=="FULL", MODEL=="Model1", VARCOMP=="GRM")
PCresid_GRMs$E[PCresid_GRMs$E=="TRAUMA"] <- "TRAUMAPCresid"
df3 <- rbind(df3, PCresid_GRMs)

TRAUMAPC1_GRMs <- df3 %>%
                  filter(SAMPLE=="FULL", MODEL=="Model1", VARCOMP=="GRM")
TRAUMAPC1_GRMs$E[TRAUMAPC1_GRMs$E=="TRAUMA"] <- "TRAUMAPC1"
df3 <- rbind(df3, TRAUMAPC1_GRMs)

ggplot(data = df3, aes(x = factor(MODEL, levels = c("GRM", "ERM", "G+E", "GxE")), y = METAH2, fill = factor(VARCOMP, levels = c("GxE", "ERM", "GRM")))) + 
  geom_bar(stat="identity") + 
  scale_fill_brewer("Variance Components", palette="Dark2") + 
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.1)) + 
  facet_grid(DV~E) + 
  xlab("Mixed Linear Models") + ylab("Proportion of Variance") +
  theme_bw()

```

The third plot will compare MLM variance components results when using ERMs capturing trauma (using trauma PC1, trauma PC2, trauma PC3)

```{r, eval=FALSE}

df4 <- df %>%
       filter(SAMPLE=="FULL", E=="TRAUMA" |E=="TRAUMAPC1_3" | E=="TRAUMAPC1" | E=="TRAUMAPC2" | E=="TRAUMAPC3")
df4$E <- factor(df4$E, levels=c("TRAUMA", "TRAUMAPC1_3", "TRAUMAPC1", "TRAUMAPC2", "TRAUMAPC3"))
df4$DV <- factor(df4$DV, levels=c("cidi", "broad", "neuro"))
       
TRAUMAPC1_GRMs <- df4 %>%
                  filter(SAMPLE=="FULL", MODEL=="GRM", VARCOMP=="GRM")
TRAUMAPC1_GRMs$E[TRAUMAPC1_GRMs$E=="TRAUMA"] <- "TRAUMAPC1"
df4 <- rbind(df4, TRAUMAPC1_GRMs)

TRAUMAPC2_GRMs <- df4 %>%
                  filter(SAMPLE=="FULL", MODEL=="GRM", VARCOMP=="GRM", E=="TRAUMA")
TRAUMAPC2_GRMs$E[TRAUMAPC2_GRMs$E=="TRAUMA"] <- "TRAUMAPC2"
df4 <- rbind(df4, TRAUMAPC2_GRMs)

TRAUMAPC3_GRMs <- df4 %>%
                  filter(SAMPLE=="FULL", MODEL=="GRM", VARCOMP=="GRM", E=="TRAUMA")
TRAUMAPC3_GRMs$E[TRAUMAPC3_GRMs$E=="TRAUMA"] <- "TRAUMAPC3"
df4 <- rbind(df4, TRAUMAPC3_GRMs)

TRAUMAPC1_3_GRMs <- df4 %>%
                  filter(SAMPLE=="FULL", MODEL=="GRM", VARCOMP=="GRM", E=="TRAUMA")
TRAUMAPC1_3_GRMs$E[TRAUMAPC1_3_GRMs$E=="TRAUMA"] <- "TRAUMAPC1_3"
df4 <- rbind(df4, TRAUMAPC1_3_GRMs)


ggplot(data = df4, aes(x = factor(MODEL, levels = c("GRM", "ERM", "G+E", "GxE")), y = METAH2, fill = factor(VARCOMP, levels = c("GxE", "ERM", "GRM")))) +
  geom_bar(stat="identity") + 
  scale_fill_brewer("Variance Components", palette="Dark2") + 
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.1)) + 
  facet_grid(DV~E) + 
  xlab("Mixed Linear Models") + ylab("Proportion of Variance") +
  theme_bw()

```

The final plot will compare MLM variance components results when using ERMs capturing trauma across different samples  

```{r, eval=FALSE}

df5 <- df %>%
       filter(SAMPLE=="FULL" | SAMPLE=="FEMALE" | SAMPLE=="MALE", E=="TRAUMA")
df5$SAMPLE <- factor(df5$SAMPLE, levels=c("FULL", "UNRELATED", "FEMALE", "MALE"))
  
plot <- ggplot(data = df5, aes(x = factor(MODEL, levels=c("Model1", "Model2", "Model3", "Model4")), y = METAH2, fill = factor(VARCOMP, levels=c("GxE", "ERM", "GRM")))) +
  geom_bar(stat="identity") + 
  scale_fill_brewer("Variance Components", palette="Dark2") + 
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.2)) + 
  #facet_wrap(~SAMPLE, ncol=3) +
  facet_grid(DV~SAMPLE) + 
  xlab("Mixed Linear Model") + ylab("Proportion of Variance") +
  theme_bw() +
  theme(axis.text.x=element_text(angle=45, hjust=1))

ggsave(file = "reml_sample_comparisons.png", plot=plot, width=10, height=5)
ggsave(file = "reml_sample_comparisons.svg", plot=plot, width=10, height=5)


```

I also create forest plots comparing the proportion of variance explained by the interaction effect across different samples  

```{r, eval}

#results directory
rm(list=ls())
library(tidyverse)
library(svglite)
################################
#reading in full trauma results# 
################################

df_full <- c()

for(depvar in c("cidi", "broad", "neuro")){
  
  for(prefix in c("n", "mn", "ms", "sw", "se")){
    
    results <- read.csv(paste0("./full_trauma/FULL_TRAUMA_", depvar, "_VCA_results_", prefix, ".csv"), header=T)

results <- results[7,c(1:3)]
results <- results %>%
           mutate(DV = depvar,
                  SAMPLE = "FULL")

df_full <- rbind(df_full, results)
}
  
meta <- read.csv(paste0("./full_trauma/FULL_TRAUMA_", depvar, "_meta_VCA_results.csv"))

meta <- meta %>%
        rename(prefix = X.meta.A.) %>%
        select(prefix, Variance, SE) %>%
        mutate(DV = depvar,
               SAMPLE = "FULL")
meta <- meta[7,]
df_full <- rbind(df_full, meta)

}

################################
#reading in full female results#
################################

df_female <- c()

for(depvar in c("cidi", "broad", "neuro")){
  
  for(prefix in c("n", "mn", "ms", "sw", "se")){
    
    results <- read.csv(paste0("./female_trauma/FEMALE_TRAUMA_", depvar, "_VCA_results_", prefix, ".csv"), header=T)

results <- results[7,c(1:3)]
results <- results %>%
           mutate(DV = depvar,
                  SAMPLE = "FEMALE")

df_female <- rbind(df_female, results)
}
  
meta <- read.csv(paste0("./female_trauma/FEMALE_TRAUMA_", depvar, "_meta_VCA_results.csv"))

meta <- meta %>%
        rename(prefix = X.meta.A.) %>%
        select(prefix, Variance, SE) %>%
        mutate(DV = depvar,
               SAMPLE = "FEMALE")
meta <- meta[7,]
df_female <- rbind(df_female, meta)

}

##############################
#reading in full male results#
##############################

df_male <- c()

for(depvar in c("cidi", "broad", "neuro")){
  
  for(prefix in c("n", "mn", "ms", "sw", "se")){
    
    results <- read.csv(paste0("./male_trauma/MALE_TRAUMA_", depvar, "_VCA_results_", prefix, ".csv"), header=T)

results <- results[7,c(1:3)]
results <- results %>%
           mutate(DV = depvar,
                  SAMPLE = "MALE")

df_male <- rbind(df_male, results)
}
  
meta <- read.csv(paste0("./male_trauma/MALE_TRAUMA_", depvar, "_meta_VCA_results.csv"))

meta <- meta %>%
        rename(prefix = X.meta.A.) %>%
        select(prefix, Variance, SE) %>%
        mutate(DV = depvar,
               SAMPLE = "MALE")
meta <- meta[7,]
df_male <- rbind(df_male, meta)

}

###################################
#combine all dfs, and create graph#
###################################

plotdf <- Reduce(function(x,y) rbind(x=x,y=y), list(df_full, df_female, df_male))

plotdf <- plotdf %>%
          mutate(META = prefix,
                 ymin = Variance - 1.96*SE,
                 ymax = Variance + 1.96*SE)
plotdf$META[plotdf$META!="meta-A"] <- "cluster"

plotdf$prefix[plotdf$prefix=="n"] <- "NORTH"
plotdf$prefix[plotdf$prefix=="mn"] <- "MIDNORTH"
plotdf$prefix[plotdf$prefix=="ms"] <- "MIDSOUTH"
plotdf$prefix[plotdf$prefix=="sw"] <- "SOUTHWEST"
plotdf$prefix[plotdf$prefix=="se"] <- "SOUTHEAST"
plotdf$prefix[plotdf$prefix=="meta-A"] <- "META-A"
plotdf$prefix <- factor(plotdf$prefix, levels = c("META-A", "SOUTHEAST", "SOUTHWEST", "MIDSOUTH", "MIDNORTH", "NORTH"))

plotdf$DV[plotdf$DV=="cidi"] <- "CIDI DEPRESSION"
plotdf$DV[plotdf$DV=="broad"] <- "BROAD DEPRESSION"
plotdf$DV[plotdf$DV=="neuro"] <- "NEUROTICISM"
plotdf$DV <- factor(plotdf$DV, levels = c ("CIDI DEPRESSION", "BROAD DEPRESSION", "NEUROTICISM"))

plotdf$SAMPLE[plotdf$SAMPLE=="FULL"] <- "WHOLE"
plotdf$SAMPLE <- factor(plotdf$SAMPLE, levels = c("WHOLE", "FEMALE", "MALE"))
plotdf <- subset(plotdf, plotdf$DV=="CIDI DEPRESSION")

plot <- ggplot(data=plotdf, aes(x=prefix, y=Variance), color=META) + 
  geom_point(aes(col=META)) + 
  geom_hline(yintercept=0, linetype=2) +
  geom_errorbar(aes(ymin=ymin, ymax=ymax, col=META), width=0.05, cex=1) + 
  scale_color_brewer("Sample", palette="Dark2") +
  scale_y_continuous(limits = c(-0.1, 1), breaks = c(seq(0, 1, by=0.2))) + 
  xlab("Geographical Cluster") + ylab("Proportion of Accounted Variance") +
  facet_wrap(~SAMPLE) + 
  #facet_grid(SAMPLE~DV) +
  coord_flip() + 
  theme_bw() +
  theme(legend.position = "none", text = element_text(size=8), axis.text.y=element_text(angle=45, hjust=1))

ggsave(file="CIDI_REML_sample_comparisons_forest.png", plot=plot, width=8, height=3)
ggsave(file="CIDI_REML_sample_comparisons_forest.svg", plot=plot, width=8, height=3)

```

Forest plots comparing the proportion of variance explained by the interaction effect with ERMs created using all trauma PCs, trauma PC1, trauma PC2, trauma PC3  

```{r, eval=FALSE}

#results directory
rm(list=ls())
library(tidyverse)

################################
#reading in full trauma results# 
################################

df_full <- c()

for(depvar in c("cidi", "broad", "neuro")){
  
  for(prefix in c("n", "mn", "ms", "sw", "se")){
    
    results <- read.csv(paste0("./full_trauma/FULL_TRAUMA_", depvar, "_VCA_results_", prefix, ".csv"), header=T)

results <- results[7,c(1:3)]
results <- results %>%
           mutate(DV = depvar,
                  SAMPLE = "FULL")

df_full <- rbind(df_full, results)
}
  
meta <- read.csv(paste0("./full_trauma/FULL_TRAUMA_", depvar, "_meta_VCA_results.csv"))

meta <- meta %>%
        rename(prefix = X.meta.A.) %>%
        select(prefix, Variance, SE) %>%
        mutate(DV = depvar,
               SAMPLE = "FULL")
meta <- meta[7,]
df_full <- rbind(df_full, meta)

}

################################
#reading in full female results#
################################

df_female <- c()

for(depvar in c("cidi", "broad", "neuro")){
  
  for(prefix in c("n", "mn", "ms", "sw", "se")){
    
    results <- read.csv(paste0("./female_trauma/FEMALE_TRAUMA_", depvar, "_VCA_results_", prefix, ".csv"), header=T)

results <- results[7,c(1:3)]
results <- results %>%
           mutate(DV = depvar,
                  SAMPLE = "FEMALE")

df_female <- rbind(df_female, results)
}
  
meta <- read.csv(paste0("./female_trauma/FEMALE_TRAUMA_", depvar, "_meta_VCA_results.csv"))

meta <- meta %>%
        rename(prefix = X.meta.A.) %>%
        select(prefix, Variance, SE) %>%
        mutate(DV = depvar,
               SAMPLE = "FEMALE")
meta <- meta[7,]
df_female <- rbind(df_female, meta)

}

##############################
#reading in full male results#
##############################

df_male <- c()

for(depvar in c("cidi", "broad", "neuro")){
  
  for(prefix in c("n", "mn", "ms", "sw", "se")){
    
    results <- read.csv(paste0("./male_trauma/MALE_TRAUMA_", depvar, "_VCA_results_", prefix, ".csv"), header=T)

results <- results[7,c(1:3)]
results <- results %>%
           mutate(DV = depvar,
                  SAMPLE = "MALE")

df_male <- rbind(df_male, results)
}
  
meta <- read.csv(paste0("./male_trauma/MALE_TRAUMA_", depvar, "_meta_VCA_results.csv"))

meta <- meta %>%
        rename(prefix = X.meta.A.) %>%
        select(prefix, Variance, SE) %>%
        mutate(DV = depvar,
               SAMPLE = "MALE")
meta <- meta[7,]
df_male <- rbind(df_male, meta)

}

###################################
#combine all dfs, and create graph#
###################################

plotdf <- Reduce(function(x,y) rbind(x=x,y=y), list(df_full, df_female, df_male))

plotdf <- plotdf %>%
          mutate(META = prefix,
                 ymin = Variance - 1.96*SE,
                 ymax = Variance + 1.96*SE)
plotdf$META[plotdf$META!="meta-A"] <- "cluster"

plotdf$prefix <- factor(plotdf$prefix, levels = c("meta-A", "se", "sw", "ms", "mn", "n"))
plotdf$DV <- factor(plotdf$DV, levels = c ("cidi", "broad", "neuro"))
plotdf$SAMPLE <- factor(plotdf$SAMPLE, levels = c("FULL", "FEMALE", "MALE"))


ggplot(data=plotdf, aes(x=prefix, y=Variance), color=META) + 
  geom_point(aes(col=META)) + 
  geom_hline(yintercept=0, linetype=2) +
  geom_errorbar(aes(ymin=ymin, ymax=ymax, col=META), width=0.05, cex=1) + 
  scale_color_brewer("Sample", palette="Dark2") +
  scale_y_continuous(limits = c(-0.1, 0.7)) + 
  xlab("Sample") + ylab("Proportion of Accounted Variance") +
  facet_grid(SAMPLE~DV) +
  coord_flip() + 
  theme_bw()
  
```








